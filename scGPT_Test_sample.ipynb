{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e14419-b9ab-43b0-920a-61da4098f535",
   "metadata": {},
   "source": [
    "Import Necessary Libraries & Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8256460-4ead-423c-a7e9-35aeaccd61d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Using 3 GPU(s) | Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda/envs/myenv/lib/python3.10/site-packages/scgpt/model/model.py:21: UserWarning: flash_attn is not installed\n",
      "  warnings.warn(\"flash_attn is not installed\")\n",
      "/data/miniconda/envs/myenv/lib/python3.10/site-packages/scgpt/model/multiomic_model.py:19: UserWarning: flash_attn is not installed\n",
      "  warnings.warn(\"flash_attn is not installed\")\n",
      "/data/miniconda/envs/myenv/lib/python3.10/site-packages/scanpy/_settings.py:488: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  IPython.display.set_matplotlib_formats(*ipython_format)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import wandb\n",
    "from scipy.sparse import issparse, csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import Vocab as VocabPybind\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Insert path for scGPT if needed\n",
    "sys.path.insert(0, \"../\")\n",
    "import scgpt as scg\n",
    "from scgpt.model import TransformerModel, AdversarialDiscriminator\n",
    "from scgpt.tokenizer import tokenize_and_pad_batch, random_mask_value\n",
    "from scgpt.loss import (\n",
    "    masked_mse_loss,\n",
    "    masked_relative_error,\n",
    "    criterion_neg_log_bernoulli,\n",
    ")\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt import SubsetsBatchSampler\n",
    "from scgpt.utils import set_seed, category_str2int, eval_scib_metrics\n",
    "\n",
    "# ✅ Set PyTorch GPU Optimization\n",
    "torch.backends.cudnn.benchmark = True  # Optimizes CUDA performance\n",
    "torch.backends.cudnn.enabled = True    # Ensures CuDNN is used\n",
    "\n",
    "# ✅ Check and Set Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"🚀 Using {num_gpus} GPU(s) | Device: {device}\")\n",
    "\n",
    "# Set default visualization parameters and ignore warnings\n",
    "sc.set_figure_params(figsize=(6, 6))\n",
    "os.environ[\"KMP_WARNINGS\"] = \"off\"\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a952aec-01e2-4977-bae6-a9902715512b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmalam007\u001b[0m (\u001b[33mmalam007-old-dominion-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/cellular_aging/results/fine-tuning/wandb/run-20250220_074347-rdkcny0t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/malam007-old-dominion-university/scGPT/runs/rdkcny0t' target=\"_blank\">snowy-snow-35</a></strong> to <a href='https://wandb.ai/malam007-old-dominion-university/scGPT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/malam007-old-dominion-university/scGPT' target=\"_blank\">https://wandb.ai/malam007-old-dominion-university/scGPT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/malam007-old-dominion-university/scGPT/runs/rdkcny0t' target=\"_blank\">https://wandb.ai/malam007-old-dominion-university/scGPT/runs/rdkcny0t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configurations Loaded. Using input style: binned\n"
     ]
    }
   ],
   "source": [
    "# ✅ **Hyperparameters and Configurations**\n",
    "hyperparameter_defaults = dict(\n",
    "    seed=0,\n",
    "    dataset_name=\"AIDA1_sample\",  # Human dataset name\n",
    "    do_train=True,\n",
    "    load_model=\"/data/cellular_aging/references/scGPT_human_pretrained_model\",  # Pretrained human model path\n",
    "    mask_ratio=0.0005,\n",
    "    epochs=50,\n",
    "    n_bins=51,\n",
    "    MLM=False,  # Explicitly add MLM key to avoid KeyError\n",
    "    MVC=False,  \n",
    "    ecs_thres=0.0,\n",
    "    dab_weight=0.0,\n",
    "    lr=1e-5,\n",
    "    batch_size=max(1, torch.cuda.device_count()),  \n",
    "    layer_size=512,\n",
    "    nlayers=12,\n",
    "    nhead=8,\n",
    "    dropout=0.2,\n",
    "    schedule_ratio=0.9,\n",
    "    save_eval_interval=5,\n",
    "    fast_transformer=True,\n",
    "    pre_norm=False,\n",
    "    amp=True, \n",
    "    include_zero_gene=False,\n",
    "    freeze=False,\n",
    "    DSBN=False,\n",
    "    DAB_separate_optim = False  # \n",
    "\n",
    ")\n",
    "\n",
    "# ✅ Initialize WandB\n",
    "run = wandb.init(\n",
    "    config=hyperparameter_defaults,\n",
    "    dir=\"/data/cellular_aging/results/fine-tuning\",\n",
    "    project=\"scGPT\",\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    ")\n",
    "config = wandb.config  # WandB converts hyperparameter_defaults into config\n",
    "\n",
    "# ✅ **Ensure Proper Input Style is Set**\n",
    "if not hasattr(config, \"input_style\"):\n",
    "    config.input_style = \"binned\"  # Default input style\n",
    "\n",
    "print(f\"✅ Configurations Loaded. Using input style: {config.input_style}\")\n",
    "\n",
    "# ✅ **Set Up Input Representations**\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
    "mask_ratio = config.mask_ratio\n",
    "mask_value = \"auto\"  # Always set to auto for masked values\n",
    "include_zero_gene = config.include_zero_gene\n",
    "max_seq_len = min(2048, 4417)  # ✅ Dynamically limit max_seq_len if needed\n",
    "n_bins = config.n_bins\n",
    "pad_value = 0  # Default padding value\n",
    "\n",
    "# ✅ **Select Input/Output Representation**\n",
    "input_style = \"binned\"\n",
    "output_style = \"binned\"\n",
    "\n",
    "# ✅ **Training Settings**\n",
    "MLM = False\n",
    "CLS = True  # Classification objective for age bin prediction\n",
    "ADV = False  # Disable adversarial training here\n",
    "CCE = False\n",
    "MVC = config.MVC\n",
    "ECS = config.ecs_thres > 0\n",
    "DAB = False\n",
    "INPUT_BATCH_LABELS = False\n",
    "input_emb_style = \"continuous\"  # Using continuous embedding style for inputs\n",
    "cell_emb_style = \"cls\"\n",
    "adv_E_delay_epochs = 0\n",
    "adv_D_delay_epochs = 0\n",
    "mvc_decoder_style = \"inner product\"\n",
    "ecs_threshold = config.ecs_thres\n",
    "dab_weight = config.dab_weight\n",
    "explicit_zero_prob = MLM and include_zero_gene\n",
    "do_sample_in_train = False and explicit_zero_prob\n",
    "per_seq_batch_sample = False\n",
    "\n",
    "# ✅ **Optimizer Settings**\n",
    "lr = config.lr\n",
    "lr_ADV = 1e-3\n",
    "batch_size = config.batch_size\n",
    "eval_batch_size = config.batch_size\n",
    "epochs = config.epochs\n",
    "schedule_interval = 1\n",
    "\n",
    "# ✅ **Model Architecture Settings**\n",
    "fast_transformer = config.fast_transformer\n",
    "fast_transformer_backend = \"flash\"\n",
    "embsize = config.layer_size\n",
    "d_hid = config.layer_size\n",
    "nlayers = config.nlayers\n",
    "nhead = config.nhead\n",
    "dropout = config.dropout\n",
    "\n",
    "# ✅ **Logging & Evaluation Settings**\n",
    "log_interval = 100\n",
    "save_eval_interval = config.save_eval_interval\n",
    "do_eval_scib_metrics = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6040e0c7-f9fe-4681-a6f7-37ad7d2e8ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes After Vocab Filtering: 23794\n",
      "🔍 Expected Number of Genes in Vocabulary: 60697\n",
      "\n",
      "📊 **Final Gene Mapping & Expression Coverage Summary:**\n",
      "🔹 Total Genes Before Vocab Filtering: 36161\n",
      "🔹 Total Genes After Vocab Filtering: 23794\n",
      "🔹 Total Expression Before Vocab Filtering: 2888279552.00\n",
      "🔹 Total Expression After Vocab Filtering: 2841698816.00\n",
      "✅ Gene Coverage After Vocab Filtering: 65.80%\n",
      "✅ Expression Coverage After Vocab Filtering: 98.39%\n",
      "✅ Sampled dataset shape: (1058, 23794)\n",
      "scGPT - INFO - Normalizing total counts ...\n",
      "scGPT - INFO - Log1p transforming ...\n",
      "scGPT - WARNING - The input data seems to be already log1p transformed. Set `log1p=False` to avoid double log1p transform.\n",
      "scGPT - INFO - Binning data ...\n",
      "✅ Preprocessing applied. Available layers: KeysView(Layers with keys: X_normed, X_log1p, X_binned)\n",
      "🔍 Total Genes in Sampled Dataset: 23794\n",
      "🔍 Total Genes in `filtered_gene_symbols`: 23794\n",
      "🔍 First 10 genes: ['MIR1302-2HG', 'FAM138A', 'OR4F5', 'OR4F29', 'OR4F16', 'LINC01409', 'FAM87B', 'LINC01128', 'LINC00115', 'FAM41C']\n",
      "🔍 `values_tensor` shape: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n"
     ]
    }
   ],
   "source": [
    "# ✅ **Load full dataset (AnnData format)**\n",
    "adata = sc.read_h5ad('/data/cellular_aging/dataset/AIDA.h5ad')\n",
    "\n",
    "# ✅ Track Total Expression Before Filtering\n",
    "total_expression_before = adata.X.sum()\n",
    "\n",
    "# ✅ Load FINAL gene mapping (from BioMart + MyGene.info)\n",
    "df_final_mapping = pd.read_csv(\"final_gene_mapping.csv\")\n",
    "final_gene_dict = dict(zip(df_final_mapping[\"ensembl_id\"], df_final_mapping[\"gene_symbol\"]))\n",
    "\n",
    "# ✅ Extract Ensembl IDs & Apply Gene Mapping\n",
    "adata.var[\"ensembl_id\"] = adata.var_names.str.split(\".\").str[0]\n",
    "adata.var[\"gene_symbol\"] = adata.var[\"ensembl_id\"].map(final_gene_dict)\n",
    "\n",
    "# ✅ Load `vocab.json`\n",
    "vocab_path = \"/data/cellular_aging/references/scGPT_human_pretrained_model/vocab.json\"\n",
    "with open(vocab_path, \"r\") as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "# ✅ Convert vocab genes to a set for fast lookup\n",
    "vocab_genes = set(vocab.keys())\n",
    "\n",
    "# ✅ Filter dataset to keep only genes with symbols in `vocab.json`\n",
    "adata_filtered_vocab = adata[:, adata.var[\"gene_symbol\"].isin(vocab_genes)].copy()\n",
    "\n",
    "# ✅ Debugging: Check the number of genes after filtering\n",
    "print(f\"🔍 Total Genes After Vocab Filtering: {adata_filtered_vocab.shape[1]}\")\n",
    "print(f\"🔍 Expected Number of Genes in Vocabulary: {len(vocab_genes)}\")\n",
    "\n",
    "# ✅ Track Total Expression After Filtering\n",
    "total_expression_after = adata_filtered_vocab.X.sum()\n",
    "\n",
    "# ✅ Compute Gene & Expression Coverage\n",
    "gene_coverage_vocab = (adata_filtered_vocab.shape[1] / adata.shape[1]) * 100\n",
    "expression_coverage_vocab = (total_expression_after / total_expression_before) * 100\n",
    "\n",
    "# ✅ Print Final Summary\n",
    "print(\"\\n📊 **Final Gene Mapping & Expression Coverage Summary:**\")\n",
    "print(f\"🔹 Total Genes Before Vocab Filtering: {adata.shape[1]}\")\n",
    "print(f\"🔹 Total Genes After Vocab Filtering: {adata_filtered_vocab.shape[1]}\")\n",
    "print(f\"🔹 Total Expression Before Vocab Filtering: {total_expression_before:.2f}\")\n",
    "print(f\"🔹 Total Expression After Vocab Filtering: {total_expression_after:.2f}\")\n",
    "print(f\"✅ Gene Coverage After Vocab Filtering: {gene_coverage_vocab:.2f}%\")\n",
    "print(f\"✅ Expression Coverage After Vocab Filtering: {expression_coverage_vocab:.2f}%\")\n",
    "\n",
    "# ✅ Ensure Sample Size is Valid\n",
    "sample_fraction = 0.001  # Adjust as needed\n",
    "num_sample = max(1, int(sample_fraction * adata_filtered_vocab.n_obs))  # Avoid zero or negative samples\n",
    "num_sample = min(num_sample, adata_filtered_vocab.n_obs)  # Prevent exceeding dataset size\n",
    "\n",
    "# ✅ Perform Random Sampling\n",
    "random_indices = np.random.choice(adata_filtered_vocab.n_obs, num_sample, replace=False)\n",
    "adata_sample = adata_filtered_vocab[random_indices, :].copy()\n",
    "print(f\"✅ Sampled dataset shape: {adata_sample.shape}\")\n",
    "\n",
    "# ✅ Convert to Sparse Format (if not already sparse)\n",
    "if not issparse(adata_sample.X):\n",
    "    adata_sample.X = csr_matrix(adata_sample.X)\n",
    "\n",
    "# ✅ Apply Preprocessing ONLY to the Sampled Data\n",
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",\n",
    "    filter_gene_by_counts=False,\n",
    "    filter_cell_by_counts=False,\n",
    "    normalize_total=True,\n",
    "    result_normed_key=\"X_normed\",\n",
    "    log1p=True,\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=False,\n",
    "    hvg_flavor=\"seurat_v3\",\n",
    "    binning=config.n_bins,  # Use binning defined in the config\n",
    "    result_binned_key=\"X_binned\",\n",
    ")\n",
    "\n",
    "# ✅ Apply Preprocessing to the Sampled Data (do not alter the full dataset)\n",
    "preprocessor(adata_sample, batch_key=None)\n",
    "\n",
    "# ✅ Ensure Preprocessing was Applied Correctly\n",
    "print(f\"✅ Preprocessing applied. Available layers: {adata_sample.layers.keys()}\")\n",
    "\n",
    "# ✅ Ensure Gene Symbols are Retained in Sampled Data\n",
    "if \"gene_symbol\" not in adata_sample.var.columns:\n",
    "    print(\"❌ Warning: `gene_symbol` column missing in `adata_sample`. Reassigning from `adata_filtered_vocab`.\")\n",
    "    adata_sample.var[\"gene_symbol\"] = adata_filtered_vocab.var[\"gene_symbol\"]\n",
    "\n",
    "# ✅ Extract Filtered Gene Symbols from Sampled Data\n",
    "filtered_gene_symbols = adata_sample.var[\"gene_symbol\"].tolist()\n",
    "\n",
    "# ✅ Debugging: Check Gene Count After Sampling\n",
    "print(f\"🔍 Total Genes in Sampled Dataset: {adata_sample.shape[1]}\")\n",
    "print(f\"🔍 Total Genes in `filtered_gene_symbols`: {len(filtered_gene_symbols)}\")\n",
    "print(f\"🔍 First 10 genes: {filtered_gene_symbols[:10]}\")\n",
    "\n",
    "# ✅ Check that the sampled genes are a subset of the vocabulary\n",
    "if not set(filtered_gene_symbols).issubset(vocab_genes):\n",
    "    print(\"⚠️ Warning: Some genes in the sampled data are missing in `vocab.json`!\")\n",
    "\n",
    "# ✅ Ensure correct preprocessing layer is used to create the input tensor\n",
    "if \"X_binned\" in adata_sample.layers:\n",
    "    data_layer = adata_sample.layers[\"X_binned\"]\n",
    "elif \"X_normed\" in adata_sample.layers:\n",
    "    data_layer = adata_sample.layers[\"X_normed\"]\n",
    "elif \"X_log1p\" in adata_sample.layers:\n",
    "    data_layer = adata_sample.layers[\"X_log1p\"]\n",
    "else:\n",
    "    raise ValueError(\"❌ No valid processed data layer found in `adata_sample`!\")\n",
    "\n",
    "# ✅ Convert sparse matrix to dense format **before** creating tensors\n",
    "if issparse(data_layer):\n",
    "    data_layer = data_layer.toarray()\n",
    "\n",
    "# ✅ Create Tensors and Move to GPU\n",
    "values_tensor = torch.tensor(data_layer, dtype=torch.float32, device=\"cuda\")  # Move tensor to GPU\n",
    "\n",
    "# ✅ Debugging: Check if `values_tensor` shape matches the number of sampled genes\n",
    "print(f\"🔍 `values_tensor` shape: {values_tensor.shape}\")\n",
    "\n",
    "num_sampled_genes = len(filtered_gene_symbols)\n",
    "if values_tensor.shape[1] != num_sampled_genes:\n",
    "    raise ValueError(\n",
    "        f\"❌ Mismatch: `values_tensor` has {values_tensor.shape[1]} features, \"\n",
    "        f\"but `filtered_gene_symbols` has {num_sampled_genes} genes. Fix dataset filtering.\"\n",
    "    )\n",
    "\n",
    "print(f\"✅ `values_tensor` shape after filtering: {values_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70844b4b-910f-427a-b658-1e8ded24c50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total Samples: 1058\n",
      "🔹 Train Samples: 846 (79.96%)\n",
      "🔹 Test Samples: 212 (20.04%)\n",
      "✅ Assigned 2 unique batch labels (Train/Test Split).\n"
     ]
    }
   ],
   "source": [
    "# ✅ Ensure the index is properly formatted for splitting as integer indices\n",
    "obs_index = np.arange(adata_sample.n_obs, dtype=np.int64)  # Ensure integer type\n",
    "\n",
    "# ✅ Split Data into Training (80%) and Testing (20%)\n",
    "train_idx, test_idx = train_test_split(obs_index, test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ Convert to NumPy arrays for efficient indexing\n",
    "train_idx = np.array(train_idx, dtype=np.int64)\n",
    "test_idx = np.array(test_idx, dtype=np.int64)\n",
    "\n",
    "# ✅ Debug: Print dataset size and split verification\n",
    "print(f\"✅ Total Samples: {adata_sample.n_obs}\")\n",
    "print(f\"🔹 Train Samples: {len(train_idx)} ({len(train_idx) / adata_sample.n_obs * 100:.2f}%)\")\n",
    "print(f\"🔹 Test Samples: {len(test_idx)} ({len(test_idx) / adata_sample.n_obs * 100:.2f}%)\")\n",
    "\n",
    "# ✅ Assign `batch_id` within the Sampled Data\n",
    "adata_sample = adata_sample.copy()  # Avoid pandas SettingWithCopyWarning\n",
    "adata_sample.obs[\"batch_id\"] = 0  # Initialize all cells as train (batch 0)\n",
    "adata_sample.obs.iloc[test_idx, adata_sample.obs.columns.get_loc(\"batch_id\")] = 1  # Mark test cells as batch 1\n",
    "\n",
    "# ✅ Convert to Numeric Batch Labels and Ensure Tensor Format\n",
    "batch_ids = torch.tensor(adata_sample.obs[\"batch_id\"].values, dtype=torch.long, device=\"cuda\")  # Move to GPU\n",
    "\n",
    "# ✅ Debugging: Check batch label distribution\n",
    "num_batch_labels = batch_ids.unique().numel()\n",
    "print(f\"✅ Assigned {num_batch_labels} unique batch labels (Train/Test Split).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ccb0fa-4531-44a7-9418-7fe297a2094d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 5 unique age categories.\n",
      "🔹 Age Tensor Shape: torch.Size([1058])\n",
      "🔹 First 10 Age Labels: [1, 3, 3, 0, 3, 1, 2, 0, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "# ✅ **Extract Numeric Age from Development Stage (within the Sampled Data)**\n",
    "age_col = \"development_stage\"\n",
    "if \"numeric_age\" not in adata_sample.obs.columns:\n",
    "    adata_sample.obs[\"numeric_age\"] = (\n",
    "        adata_sample.obs[age_col]\n",
    "        .astype(str)\n",
    "        .str.extract(r\"(\\d+)\")  # Extracts numeric values from text\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "# ✅ Handle missing values (fill with median to avoid NaNs)\n",
    "adata_sample.obs[\"numeric_age\"].fillna(adata_sample.obs[\"numeric_age\"].median(), inplace=True)\n",
    "\n",
    "# ✅ **Convert Numeric Age to Categorical Labels using qcut**\n",
    "# Here, retbins=True returns the bin edges as well.\n",
    "age_codes, bin_edges = pd.qcut(\n",
    "    adata_sample.obs[\"numeric_age\"],\n",
    "    q=5,\n",
    "    labels=False,\n",
    "    retbins=True,\n",
    "    duplicates=\"drop\"  # In case there are duplicate bin edges\n",
    ")\n",
    "\n",
    "adata_sample.obs[\"age_id\"] = age_codes.astype(np.int64)  # Ensure integer format\n",
    "\n",
    "# ✅ **Create Age Category Mapping from Bin Edges**\n",
    "id2type = {\n",
    "    i: f\"{bin_edges[i]:.1f} - {bin_edges[i+1]:.1f}\"\n",
    "    for i in range(len(bin_edges) - 1)\n",
    "}\n",
    "\n",
    "# ✅ Convert Age Labels to PyTorch Tensor and Move to GPU\n",
    "age_labels_tensor = torch.tensor(\n",
    "    adata_sample.obs[\"age_id\"].values, dtype=torch.long, device=\"cuda\"\n",
    ")\n",
    "\n",
    "# ✅ Debugging: Count Unique Age Groups and Ensure Proper Formatting\n",
    "num_types = len(id2type)\n",
    "print(f\"✅ Found {num_types} unique age categories.\")\n",
    "print(f\"🔹 Age Tensor Shape: {age_labels_tensor.shape}\")\n",
    "print(f\"🔹 First 10 Age Labels: {age_labels_tensor[:10].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bca0edb3-9878-49c2-bab2-c7ed866b08d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tokenization Complete! Train Data: 846 samples, Test Data: 212 samples.\n"
     ]
    }
   ],
   "source": [
    "# ✅ **Ensure `input_style` is correctly mapped to available preprocessing layers**\n",
    "input_style = getattr(config, \"input_style\", \"binned\")  # Default to \"binned\" if missing\n",
    "\n",
    "input_layer_key = {\n",
    "    \"normed_raw\": \"X_normed\",\n",
    "    \"log1p\": \"X_log1p\",\n",
    "    \"binned\": \"X_binned\",\n",
    "}.get(input_style, \"X_binned\")  # Default to \"X_binned\" if invalid\n",
    "\n",
    "# ✅ **Ensure preprocessing was applied correctly**\n",
    "if input_layer_key not in adata_sample.layers:\n",
    "    raise KeyError(f\"❌ Layer {input_layer_key} not found in adata_sample! Available: {adata_sample.layers.keys()}\")\n",
    "\n",
    "# ✅ **Convert Gene Symbols to Vocab Indices**\n",
    "gene_symbols = adata_sample.var[\"gene_symbol\"].tolist()\n",
    "gene_ids_np = np.array([vocab.get(gene, vocab.get(pad_token, 0)) for gene in gene_symbols], dtype=np.int64)  # Map to vocab indices\n",
    "\n",
    "# ✅ **Tokenize and Pad Gene Expression Data**\n",
    "tokenized_data = tokenize_and_pad_batch(\n",
    "    adata_sample.layers[input_layer_key],  # Select appropriate input style\n",
    "    gene_ids=gene_ids_np,  # Now using vocab-mapped indices\n",
    "    max_len=max_seq_len,\n",
    "    vocab=vocab,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=0,\n",
    "    append_cls=True,  # Append <cls> token at the beginning\n",
    "    include_zero_gene=config.include_zero_gene,\n",
    ")\n",
    "\n",
    "# ✅ **Extract Tokenized Values**\n",
    "gene_ids = tokenized_data[\"genes\"]\n",
    "input_values = tokenized_data[\"values\"]\n",
    "\n",
    "# ✅ **Randomly Mask Some Values for MLM (If Enabled)**\n",
    "if config.MLM:  # Ensure MLM is fetched from config\n",
    "    input_values = random_mask_value(\n",
    "        input_values,\n",
    "        mask_ratio=config.mask_ratio,\n",
    "        mask_value=\"auto\",  # Always set to auto for masked values\n",
    "        pad_value=0,\n",
    "    )\n",
    "\n",
    "# ✅ **Extract PyTorch Tensors and Move to GPU**\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "gene_ids_tensor = torch.tensor(gene_ids, dtype=torch.long, device=device)\n",
    "values_tensor = torch.tensor(input_values, dtype=torch.float32, device=device)\n",
    "target_values_tensor = torch.tensor(tokenized_data[\"values\"], dtype=torch.float32, device=device)\n",
    "batch_labels_tensor = torch.tensor(adata_sample.obs[\"batch_id\"].values, dtype=torch.long, device=device)\n",
    "age_labels_tensor = torch.tensor(adata_sample.obs[\"age_id\"].values, dtype=torch.long, device=device)\n",
    "\n",
    "# ✅ **Split Each Tensor into Train & Test Using Correct Indices**\n",
    "obs_index = np.arange(adata_sample.n_obs)  # Use numerical indices\n",
    "\n",
    "train_idx, test_idx = train_test_split(obs_index, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "# ✅ Convert indices to NumPy arrays for efficiency\n",
    "train_idx = np.array(train_idx, dtype=np.int64)\n",
    "test_idx = np.array(test_idx, dtype=np.int64)\n",
    "\n",
    "# ✅ **Create Train/Test Masks**\n",
    "train_mask = torch.tensor(np.isin(obs_index, train_idx), dtype=torch.bool, device=device)\n",
    "test_mask = torch.tensor(np.isin(obs_index, test_idx), dtype=torch.bool, device=device)\n",
    "\n",
    "# ✅ **Ensure Train/Test Split Uses the Correct Sampled Indices**\n",
    "train_data = {\n",
    "    \"gene_ids\": gene_ids_tensor[train_mask],\n",
    "    \"values\": values_tensor[train_mask],\n",
    "    \"target_values\": target_values_tensor[train_mask],\n",
    "    \"batch_labels\": batch_labels_tensor[train_mask],\n",
    "    \"age_labels\": age_labels_tensor[train_mask],\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "    \"gene_ids\": gene_ids_tensor[test_mask],\n",
    "    \"values\": values_tensor[test_mask],\n",
    "    \"target_values\": target_values_tensor[test_mask],\n",
    "    \"batch_labels\": batch_labels_tensor[test_mask],\n",
    "    \"age_labels\": age_labels_tensor[test_mask],\n",
    "}\n",
    "\n",
    "# ✅ Debugging: Print Train/Test Set Sizes\n",
    "print(f\"✅ Tokenization Complete! Train Data: {train_data['gene_ids'].shape[0]} samples, Test Data: {test_data['gene_ids'].shape[0]} samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c3a1631-2449-44b4-9810-27b7f68826cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Transformer Model Initialized on cuda using 3 GPU(s).\n"
     ]
    }
   ],
   "source": [
    "# ✅ **Free Up GPU Memory Before Initializing Model**\n",
    "torch.cuda.empty_cache()  # Prevent memory fragmentation issues\n",
    "\n",
    "# ✅ **Initialize Transformer Model**\n",
    "model = TransformerModel(\n",
    "    ntoken=len(vocab),  # Size of vocabulary\n",
    "    d_model=config.layer_size,  # Embedding dimension\n",
    "    nhead=config.nhead,  # Number of attention heads\n",
    "    d_hid=config.layer_size,  # Hidden layer size\n",
    "    nlayers=config.nlayers,  # Number of Transformer layers\n",
    "    nlayers_cls=3,  # Number of classification layers\n",
    "    n_cls=num_types if CLS else 1,  # Classification categories\n",
    "    vocab=vocab,  # Vocabulary mapping\n",
    "    dropout=config.dropout,  # Dropout probability\n",
    "    pad_token=pad_token,  # Padding token\n",
    "    pad_value=0,  # Padding value for embeddings\n",
    "    do_mvc=MVC,  # Enable masked value prediction\n",
    "    use_batch_labels=INPUT_BATCH_LABELS,  # Include batch labels\n",
    "    num_batch_labels=num_batch_labels,  # Number of batch labels\n",
    "    domain_spec_batchnorm=config.DSBN,  # Enable domain-specific batch norm\n",
    "    input_emb_style=input_emb_style,  # Input embedding type\n",
    "    n_input_bins=config.n_bins + 2,  # Number of input bins\n",
    "    cell_emb_style=cell_emb_style,  # Cell embedding type\n",
    "    mvc_decoder_style=mvc_decoder_style,  # MVC decoder style\n",
    "    ecs_threshold=ecs_threshold,  # Elastic cell similarity threshold\n",
    "    explicit_zero_prob=explicit_zero_prob,  # Explicit zero probability modeling\n",
    "    use_fast_transformer=fast_transformer,  # Use optimized Transformer\n",
    "    fast_transformer_backend=fast_transformer_backend,  # Transformer backend\n",
    "    pre_norm=config.pre_norm,  # Pre-normalization setting\n",
    ")\n",
    "\n",
    "# ✅ **Multi-GPU Support: Wrap Model with DataParallel**\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "if num_gpus > 1:\n",
    "    model = torch.nn.DataParallel(model)  # ✅ Enables training on multiple GPUs\n",
    "\n",
    "# ✅ **Move Model to GPU**\n",
    "model.to(device)\n",
    "\n",
    "print(f\"✅ Transformer Model Initialized on {device} using {num_gpus} GPU(s).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f352010d-15c3-47e3-b820-051e897b2b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded pretrained model from /data/cellular_aging/references/scGPT_human_pretrained_model/best_model.pt on 3 GPU(s).\n"
     ]
    }
   ],
   "source": [
    "# ✅ Move Model to GPU/CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "# ✅ Apply DataParallel if multiple GPUs are available\n",
    "if num_gpus > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# ✅ Load Pretrained Weights (If Available)\n",
    "if config.load_model:\n",
    "    model_checkpoint = Path(config.load_model) / \"best_model.pt\"\n",
    "    \n",
    "    try:\n",
    "        # ✅ Load checkpoint while handling multi-GPU and single-GPU compatibility\n",
    "        state_dict = torch.load(model_checkpoint, map_location=device)\n",
    "\n",
    "        # ✅ Handle DataParallel model loading mismatch\n",
    "        if num_gpus > 1:\n",
    "            # If model is wrapped in DataParallel, adjust the state_dict keys\n",
    "            from collections import OrderedDict\n",
    "            new_state_dict = OrderedDict()\n",
    "            for k, v in state_dict.items():\n",
    "                new_state_dict[k.replace(\"module.\", \"\")] = v  # Remove \"module.\" prefix\n",
    "            model.load_state_dict(new_state_dict, strict=False)\n",
    "        else:\n",
    "            model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "        print(f\"✅ Loaded pretrained model from {model_checkpoint} on {num_gpus} GPU(s).\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Warning: Failed to load full model. {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31cf0cb4-0ca6-4a78-b183-cac8b036fe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:45:50,051 - INFO - 📌 Pre-freeze: 51,334,150, Post-freeze: 51,334,150\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# ✅ Configure Logger\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ✅ Helper function to count trainable parameters\n",
    "def count_params(model):\n",
    "    \"\"\"Count trainable parameters, handling DataParallel models correctly.\"\"\"\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model = model.module  # Extract actual model for parameter counting\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# ✅ Count Parameters Before Freezing\n",
    "pre_freeze = count_params(model)\n",
    "\n",
    "# ✅ Handle Freezing Logic (Works with Multi-GPU)\n",
    "if config.freeze:\n",
    "    if isinstance(model, torch.nn.DataParallel):  \n",
    "        model_to_freeze = model.module  # Extract actual model from DataParallel\n",
    "    else:\n",
    "        model_to_freeze = model\n",
    "\n",
    "    for name, p in model_to_freeze.named_parameters():\n",
    "        if \"encoder\" in name and \"transformer_encoder\" not in name:\n",
    "            print(f\"🔒 Freezing weights for: {name}\")\n",
    "            p.requires_grad = False\n",
    "\n",
    "# ✅ Count Parameters After Freezing\n",
    "post_freeze = count_params(model)\n",
    "\n",
    "# ✅ Log Parameter Changes\n",
    "logger.info(f\"📌 Pre-freeze: {pre_freeze:,}, Post-freeze: {post_freeze:,}\")  # Format with commas for readability\n",
    "\n",
    "# ✅ Log to WandB\n",
    "wandb.log({\n",
    "    \"info/pre_freeze_param_count\": pre_freeze,\n",
    "    \"info/post_freeze_param_count\": post_freeze\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d9a2ff9-600a-498e-bce8-6cb230ae1848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_wandb_metrics():\n",
    "    \"\"\"\n",
    "    Define WandB metrics to monitor training and validation performance.\n",
    "    These metrics help track key performance indicators such as mean squared error (MSE),\n",
    "    mean relative error (MRE), and any additional metrics (like domain adaptation loss or test metrics).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ✅ Ensure WandB is initialized before defining metrics\n",
    "        if wandb.run is None:\n",
    "            logger.warning(\"⚠️ WandB is not initialized. Skipping metric definition.\")\n",
    "            return\n",
    "        \n",
    "        # ✅ Define primary validation metrics\n",
    "        wandb.define_metric(\"epoch\")  # Ensure epoch is tracked correctly\n",
    "        wandb.define_metric(\"valid/mse\", summary=\"min\", step_metric=\"epoch\")\n",
    "        wandb.define_metric(\"valid/mre\", summary=\"min\", step_metric=\"epoch\")\n",
    "        wandb.define_metric(\"valid/dab\", summary=\"min\", step_metric=\"epoch\")\n",
    "        wandb.define_metric(\"valid/sum_mse_dab\", summary=\"min\", step_metric=\"epoch\")\n",
    "        wandb.define_metric(\"test/avg_bio\", summary=\"max\")\n",
    "\n",
    "        logger.info(\"✅ WandB metrics successfully defined.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Error defining WandB metrics: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0fc15cf-41c9-4bce-9141-8ee040c9bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, loader: DataLoader, epoch: int) -> None:\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    # ✅ Handle DataParallel model for multi-GPU training\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model_to_train = model.module  # Extract actual model\n",
    "    else:\n",
    "        model_to_train = model\n",
    "\n",
    "    (\n",
    "        total_loss,\n",
    "        total_mse,\n",
    "        total_cls,\n",
    "        total_cce,\n",
    "        total_mvc,\n",
    "        total_ecs,\n",
    "        total_dab,\n",
    "        total_adv_E,\n",
    "        total_adv_D,\n",
    "        total_zero_log_prob,\n",
    "        total_mvc_zero_log_prob,\n",
    "    ) = (0.0,) * 11\n",
    "    \n",
    "    total_error = 0.0\n",
    "    start_time = time.time()\n",
    "    num_batches = len(loader)\n",
    "\n",
    "    for batch, batch_data in enumerate(loader):\n",
    "        input_gene_ids = batch_data[\"gene_ids\"].to(device, non_blocking=True)\n",
    "        input_values = batch_data[\"values\"].to(device, non_blocking=True)\n",
    "        target_values = batch_data[\"target_values\"].to(device, non_blocking=True)\n",
    "        batch_labels = batch_data[\"batch_labels\"].to(device, non_blocking=True)\n",
    "        age_labels = batch_data[\"age_labels\"].to(device, non_blocking=True)\n",
    "        src_key_padding_mask = input_gene_ids.eq(vocab[pad_token])\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=config.amp):  # ✅ Automatic Mixed Precision (AMP) for efficiency\n",
    "            output_dict = model_to_train(\n",
    "                input_gene_ids,\n",
    "                input_values,\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                batch_labels=batch_labels if INPUT_BATCH_LABELS or config.DSBN else None,\n",
    "                CLS=CLS,\n",
    "                CCE=CCE,\n",
    "                MVC=MVC,\n",
    "                ECS=ECS,\n",
    "                do_sample=do_sample_in_train,\n",
    "            )\n",
    "            masked_positions = input_values.eq(mask_value)  # Identify positions to predict\n",
    "            loss = 0.0\n",
    "            metrics_to_log = {}\n",
    "\n",
    "            # ✅ Masked Language Modeling Loss\n",
    "            if MLM:\n",
    "                loss_mse = criterion(output_dict[\"mlm_output\"], target_values, masked_positions)\n",
    "                loss += loss_mse\n",
    "                metrics_to_log[\"train/mse\"] = loss_mse.item()\n",
    "\n",
    "            # ✅ Explicit Zero Probability Loss\n",
    "            if explicit_zero_prob:\n",
    "                loss_zero_log_prob = criterion_neg_log_bernoulli(\n",
    "                    output_dict[\"mlm_zero_probs\"], target_values, masked_positions\n",
    "                )\n",
    "                loss += loss_zero_log_prob\n",
    "                metrics_to_log[\"train/nzlp\"] = loss_zero_log_prob.item()\n",
    "\n",
    "            # ✅ Classification Loss\n",
    "            if CLS:\n",
    "                loss_cls = criterion_cls(output_dict[\"cls_output\"], age_labels)\n",
    "                loss += loss_cls\n",
    "                metrics_to_log[\"train/cls\"] = loss_cls.item()\n",
    "                error_rate = 1 - (output_dict[\"cls_output\"].argmax(1) == age_labels).sum().item() / age_labels.size(0)\n",
    "\n",
    "            # ✅ Contrastive Cell Embedding Loss\n",
    "            if CCE:\n",
    "                loss_cce = 10 * output_dict[\"loss_cce\"]\n",
    "                loss += loss_cce\n",
    "                metrics_to_log[\"train/cce\"] = loss_cce.item()\n",
    "\n",
    "            # ✅ Masked Value Prediction Loss\n",
    "            if MVC:\n",
    "                loss_mvc = criterion(output_dict[\"mvc_output\"], target_values, masked_positions)\n",
    "                loss += loss_mvc\n",
    "                metrics_to_log[\"train/mvc\"] = loss_mvc.item()\n",
    "\n",
    "            if MVC and explicit_zero_prob:\n",
    "                loss_mvc_zero_log_prob = criterion_neg_log_bernoulli(\n",
    "                    output_dict[\"mvc_zero_probs\"], target_values, masked_positions\n",
    "                )\n",
    "                loss += loss_mvc_zero_log_prob\n",
    "                metrics_to_log[\"train/mvc_nzlp\"] = loss_mvc_zero_log_prob.item()\n",
    "\n",
    "            # ✅ Elastic Cell Similarity Loss\n",
    "            if ECS:\n",
    "                loss_ecs = 10 * output_dict[\"loss_ecs\"]\n",
    "                loss += loss_ecs\n",
    "                metrics_to_log[\"train/ecs\"] = loss_ecs.item()\n",
    "\n",
    "            # ✅ Domain Adaptation Loss\n",
    "            if DAB:\n",
    "                loss_dab = criterion_dab(output_dict[\"dab_output\"], batch_labels)\n",
    "                loss += dab_weight * loss_dab\n",
    "                metrics_to_log[\"train/dab\"] = loss_dab.item()\n",
    "\n",
    "        # ✅ Backpropagation\n",
    "        optimizer.zero_grad(set_to_none=True)  # More efficient than model.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "\n",
    "        # ✅ Clip Gradients to Prevent Exploding Gradients\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            model.parameters(), 1.0, \n",
    "            error_if_nonfinite=False if scaler.is_enabled() else True\n",
    "        )\n",
    "\n",
    "        # ✅ Step the Optimizer and Update the Scaler\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # ✅ Adversarial Training (If Enabled)\n",
    "        if ADV:\n",
    "            output_dict = model_to_train(\n",
    "                input_gene_ids,\n",
    "                input_values,\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                batch_labels=batch_labels if INPUT_BATCH_LABELS or config.DSBN else None,\n",
    "                CLS=CLS,\n",
    "                CCE=CCE,\n",
    "                MVC=MVC,\n",
    "                ECS=ECS,\n",
    "                do_sample=do_sample_in_train,\n",
    "            )\n",
    "\n",
    "            # ✅ Train Discriminator\n",
    "            loss_adv_D = criterion_adv(discriminator(output_dict[\"cell_emb\"].detach()), batch_labels)\n",
    "            if epoch > adv_D_delay_epochs:\n",
    "                optimizer_D.zero_grad(set_to_none=True)\n",
    "                loss_adv_D.backward()\n",
    "                optimizer_D.step()\n",
    "\n",
    "            # ✅ Train Encoder\n",
    "            loss_adv_E = -criterion_adv(discriminator(output_dict[\"cell_emb\"]), batch_labels)\n",
    "            if epoch > adv_E_delay_epochs:\n",
    "                optimizer_E.zero_grad(set_to_none=True)\n",
    "                loss_adv_E.backward()\n",
    "                optimizer_E.step()\n",
    "\n",
    "        # ✅ Log Metrics\n",
    "        wandb.log(metrics_to_log)\n",
    "\n",
    "        # ✅ Aggregate Losses\n",
    "        total_loss += loss.item()\n",
    "        total_mse += loss_mse.item() if MLM else 0.0\n",
    "        total_cls += loss_cls.item() if CLS else 0.0\n",
    "        total_cce += loss_cce.item() if CCE else 0.0\n",
    "        total_mvc += loss_mvc.item() if MVC else 0.0\n",
    "        total_ecs += loss_ecs.item() if ECS else 0.0\n",
    "        total_dab += loss_dab.item() if DAB else 0.0\n",
    "        total_adv_E += loss_adv_E.item() if ADV else 0.0\n",
    "        total_adv_D += loss_adv_D.item() if ADV else 0.0\n",
    "        total_zero_log_prob += loss_zero_log_prob.item() if explicit_zero_prob else 0.0\n",
    "        total_mvc_zero_log_prob += loss_mvc_zero_log_prob.item() if MVC and explicit_zero_prob else 0.0\n",
    "        total_error += error_rate\n",
    "\n",
    "        # ✅ Logging at Intervals\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            logger.info(\n",
    "                f\"| Epoch {epoch:3d} | Batch {batch:3d}/{num_batches:3d} | LR {lr:.5f} | Time {ms_per_batch:.2f}ms | \"\n",
    "                f\"Loss {total_loss / log_interval:.4f} | \"\n",
    "                f\"MSE {total_mse / log_interval:.4f} | \"\n",
    "                f\"CLS {total_cls / log_interval:.4f} | \"\n",
    "                f\"CCE {total_cce / log_interval:.4f} | \"\n",
    "                f\"MVC {total_mvc / log_interval:.4f} | \"\n",
    "                f\"ECS {total_ecs / log_interval:.4f} | \"\n",
    "                f\"DAB {total_dab / log_interval:.4f} | \"\n",
    "                f\"ADV_E {total_adv_E / log_interval:.4f} | \"\n",
    "                f\"ADV_D {total_adv_D / log_interval:.4f} | \"\n",
    "                f\"NZLP {total_zero_log_prob / log_interval:.4f} | \"\n",
    "                f\"MVC_NZLP {total_mvc_zero_log_prob / log_interval:.4f} | \"\n",
    "                f\"Error {total_error / log_interval:.4f}\"\n",
    "            )\n",
    "\n",
    "            total_loss = total_mse = total_cls = total_cce = total_mvc = total_ecs = total_dab = 0\n",
    "            total_adv_E = total_adv_D = total_zero_log_prob = total_mvc_zero_log_prob = total_error = 0\n",
    "            start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24783932-420d-4c8a-b9e4-8eaf9941c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, loader: DataLoader, return_raw: bool = False) -> Union[float, Tuple[float, float]]:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the validation/test dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # ✅ Handle DataParallel model for multi-GPU evaluation\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model_to_eval = model.module  # Extract actual model\n",
    "    else:\n",
    "        model_to_eval = model\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_error = 0.0\n",
    "    total_dab = 0.0\n",
    "    total_num = 0\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in loader:\n",
    "            input_gene_ids = batch_data[\"gene_ids\"].to(device, non_blocking=True)\n",
    "            input_values = batch_data[\"values\"].to(device, non_blocking=True)\n",
    "            target_values = batch_data[\"target_values\"].to(device, non_blocking=True)\n",
    "            batch_labels = batch_data[\"batch_labels\"].to(device, non_blocking=True)\n",
    "            age_labels = batch_data[\"age_labels\"].to(device, non_blocking=True)\n",
    "\n",
    "            src_key_padding_mask = input_gene_ids.eq(vocab[pad_token])\n",
    "            \n",
    "            with torch.cuda.amp.autocast(enabled=config.amp):\n",
    "                output_dict = model_to_eval(\n",
    "                    input_gene_ids,\n",
    "                    input_values,\n",
    "                    src_key_padding_mask=src_key_padding_mask,\n",
    "                    batch_labels=batch_labels if INPUT_BATCH_LABELS or config.DSBN else None,\n",
    "                    CLS=CLS,  # Only classification used here, disable MLM/CCE\n",
    "                    CCE=False,\n",
    "                    MVC=False,\n",
    "                    ECS=False,\n",
    "                    do_sample=do_sample_in_train,\n",
    "                )\n",
    "\n",
    "                output_values = output_dict[\"cls_output\"]\n",
    "                loss = criterion_cls(output_values, age_labels)\n",
    "\n",
    "                loss_dab = 0.0\n",
    "                if DAB:\n",
    "                    loss_dab = criterion_dab(output_dict[\"dab_output\"], batch_labels)\n",
    "\n",
    "            # ✅ Aggregate Metrics\n",
    "            batch_size = input_gene_ids.shape[0]\n",
    "            total_loss += loss.item() * batch_size\n",
    "            accuracy = (output_values.argmax(1) == age_labels).sum().item()\n",
    "            total_error += (1 - accuracy / batch_size) * batch_size\n",
    "            total_dab += loss_dab.item() * batch_size if DAB else 0.0\n",
    "            total_num += batch_size\n",
    "\n",
    "            preds = output_values.argmax(1).cpu().numpy()\n",
    "            predictions.append(preds)\n",
    "\n",
    "    # ✅ Compute Final Metrics\n",
    "    avg_loss = total_loss / total_num\n",
    "    avg_error = total_error / total_num\n",
    "    avg_dab = total_dab / total_num if DAB else 0.0\n",
    "    sum_mse_dab = avg_loss + dab_weight * avg_dab if DAB else avg_loss\n",
    "\n",
    "    # ✅ Log metrics to WandB\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"valid/mse\": avg_loss,\n",
    "            \"valid/err\": avg_error,\n",
    "            \"valid/dab\": avg_dab,\n",
    "            \"valid/sum_mse_dab\": sum_mse_dab,\n",
    "            \"epoch\": epoch,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ✅ Debugging Output\n",
    "    logger.info(\n",
    "        f\"✅ Evaluation Complete | Loss: {avg_loss:.4f} | Error: {avg_error:.4f} | DAB: {avg_dab:.4f}\"\n",
    "    )\n",
    "\n",
    "    if return_raw:\n",
    "        return np.concatenate(predictions, axis=0)\n",
    "\n",
    "    return avg_loss, avg_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00781e8a-5861-44c9-8423-81d0092fe67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(tokenized_train, tokenized_valid, \n",
    "                 train_batch_labels, valid_batch_labels, \n",
    "                 train_age_labels, valid_age_labels,\n",
    "                 mask_ratio, mask_value, pad_value, epoch, \n",
    "                 sort_seq_batch=False):\n",
    "    \"\"\"\n",
    "    Prepare data for training and validation, optimizing for multi-GPU.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # ✅ Apply Random Masking for Masked Language Modeling\n",
    "    masked_values_train = random_mask_value(\n",
    "        tokenized_train[\"values\"],\n",
    "        mask_ratio=mask_ratio,\n",
    "        mask_value=mask_value,\n",
    "        pad_value=pad_value,\n",
    "    )\n",
    "    masked_values_valid = random_mask_value(\n",
    "        tokenized_valid[\"values\"],\n",
    "        mask_ratio=mask_ratio,\n",
    "        mask_value=mask_value,\n",
    "        pad_value=pad_value,\n",
    "    )\n",
    "\n",
    "    # ✅ Debugging: Print Masking Information\n",
    "    print(\n",
    "        f\"🔹 Random masking applied at epoch {epoch:3d}, \"\n",
    "        f\"ratio of masked values in train: \"\n",
    "        f\"{(masked_values_train == mask_value).sum() / (masked_values_train - pad_value).count_nonzero():.4f}\"\n",
    "    )\n",
    "\n",
    "    # ✅ Extract Inputs & Targets\n",
    "    input_gene_ids_train, input_gene_ids_valid = (\n",
    "        tokenized_train[\"genes\"],\n",
    "        tokenized_valid[\"genes\"],\n",
    "    )\n",
    "    input_values_train, input_values_valid = masked_values_train, masked_values_valid\n",
    "    target_values_train, target_values_valid = (\n",
    "        tokenized_train[\"values\"],\n",
    "        tokenized_valid[\"values\"],\n",
    "    )\n",
    "\n",
    "    # ✅ Convert Batch Labels & Age Labels to PyTorch Tensors (Move to GPU)\n",
    "    tensor_batch_labels_train = torch.tensor(train_batch_labels, dtype=torch.long, device=device)\n",
    "    tensor_batch_labels_valid = torch.tensor(valid_batch_labels, dtype=torch.long, device=device)\n",
    "\n",
    "    tensor_age_labels_train = torch.tensor(train_age_labels, dtype=torch.long, device=device)\n",
    "    tensor_age_labels_valid = torch.tensor(valid_age_labels, dtype=torch.long, device=device)\n",
    "\n",
    "    # ✅ Optional Sorting for Sequence Batching\n",
    "    if sort_seq_batch:  \n",
    "        train_sort_ids = np.argsort(train_batch_labels)\n",
    "        valid_sort_ids = np.argsort(valid_batch_labels)\n",
    "\n",
    "        input_gene_ids_train = input_gene_ids_train[train_sort_ids]\n",
    "        input_values_train = input_values_train[train_sort_ids]\n",
    "        target_values_train = target_values_train[train_sort_ids]\n",
    "        tensor_batch_labels_train = tensor_batch_labels_train[train_sort_ids]\n",
    "        tensor_age_labels_train = tensor_age_labels_train[train_sort_ids]\n",
    "\n",
    "        input_gene_ids_valid = input_gene_ids_valid[valid_sort_ids]\n",
    "        input_values_valid = input_values_valid[valid_sort_ids]\n",
    "        target_values_valid = target_values_valid[valid_sort_ids]\n",
    "        tensor_batch_labels_valid = tensor_batch_labels_valid[valid_sort_ids]\n",
    "        tensor_age_labels_valid = tensor_age_labels_valid[valid_sort_ids]\n",
    "\n",
    "    # ✅ Convert Input Data to PyTorch Tensors and Move to GPU\n",
    "    train_data_pt = {\n",
    "        \"gene_ids\": torch.tensor(input_gene_ids_train, dtype=torch.long, device=device),\n",
    "        \"values\": torch.tensor(input_values_train, dtype=torch.float32, device=device),\n",
    "        \"target_values\": torch.tensor(target_values_train, dtype=torch.float32, device=device),\n",
    "        \"batch_labels\": tensor_batch_labels_train,\n",
    "        \"age_labels\": tensor_age_labels_train,\n",
    "    }\n",
    "    \n",
    "    valid_data_pt = {\n",
    "        \"gene_ids\": torch.tensor(input_gene_ids_valid, dtype=torch.long, device=device),\n",
    "        \"values\": torch.tensor(input_values_valid, dtype=torch.float32, device=device),\n",
    "        \"target_values\": torch.tensor(target_values_valid, dtype=torch.float32, device=device),\n",
    "        \"batch_labels\": tensor_batch_labels_valid,\n",
    "        \"age_labels\": tensor_age_labels_valid,\n",
    "    }\n",
    "\n",
    "    return train_data_pt, valid_data_pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74acf3a1-2d79-4bd9-a3cc-24d8a33a10bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Dataset wrapper\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, data: Dict[str, torch.Tensor]):\n",
    "        # ✅ Ensure tensors are on CPU before passing to DataLoader\n",
    "        self.data = {k: v.cpu() for k, v in data.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data[\"gene_ids\"].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.data.items()}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ✅ Data loader preparation function\n",
    "def prepare_dataloader(\n",
    "    data_pt: Dict[str, torch.Tensor],\n",
    "    batch_size: int,\n",
    "    shuffle: bool = False,\n",
    "    intra_domain_shuffle: bool = False,\n",
    "    drop_last: bool = False,\n",
    "    num_workers: Optional[int] = None,\n",
    ") -> DataLoader:\n",
    "    \"\"\"\n",
    "    Prepare the DataLoader optimized for multi-GPU training.\n",
    "    \"\"\"\n",
    "\n",
    "    # ✅ Set number of workers dynamically based on available CPU cores\n",
    "    if num_workers is None:\n",
    "        num_workers = max(1, min(os.cpu_count() // 2, batch_size // 2))  # Avoid excessive CPU usage\n",
    "\n",
    "    # ✅ Check if running on GPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    \n",
    "    # ✅ Pin memory for efficient GPU data transfer\n",
    "    pin_memory = use_cuda\n",
    "\n",
    "    dataset = SeqDataset(data_pt)\n",
    "\n",
    "    if per_seq_batch_sample:\n",
    "        # ✅ Handle per-sequence batch sampling\n",
    "        subsets = []\n",
    "        \n",
    "        # ✅ Ensure batch labels are on CPU before converting to NumPy\n",
    "        batch_labels_array = data_pt[\"batch_labels\"].cpu().numpy()\n",
    "\n",
    "        for batch_label in np.unique(batch_labels_array):\n",
    "            batch_indices = np.where(batch_labels_array == batch_label)[0].tolist()\n",
    "            subsets.append(batch_indices)\n",
    "\n",
    "        data_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_sampler=SubsetsBatchSampler(\n",
    "                subsets,\n",
    "                batch_size,\n",
    "                intra_subset_shuffle=intra_domain_shuffle,\n",
    "                inter_subset_shuffle=shuffle,\n",
    "                drop_last=drop_last,\n",
    "            ),\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=pin_memory,\n",
    "        )\n",
    "        return data_loader\n",
    "\n",
    "    # ✅ Standard DataLoader for non-sequence-batched data\n",
    "    data_loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "053f74af-3b26-40dd-ac3b-251dd7b37a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:45:50,113 - INFO - ✅ WandB metrics successfully defined.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch   1, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:46:05,988 - INFO - | Epoch   1 | Batch 100/282 | LR 0.00001 | Time 155.57ms | Loss 1.7141 | MSE 0.0000 | CLS 1.7141 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.8333\n",
      "2025-02-20 07:46:19,726 - INFO - | Epoch   1 | Batch 200/282 | LR 0.00001 | Time 137.38ms | Loss 1.6763 | MSE 0.0000 | CLS 1.6763 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.8533\n",
      "2025-02-20 07:46:37,220 - INFO - ✅ Evaluation Complete | Loss: 1.6419 | Error: 0.7642 | DAB: 0.0000\n",
      "2025-02-20 07:46:37,222 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:46:37,223 - INFO - | End of Epoch   1 | Time: 47.11s | Validation Loss/MSE: 1.6419 | Error Rate: 0.7642\n",
      "2025-02-20 07:46:37,223 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:46:37,242 - INFO - ✅ New Best Model Saved at Epoch 1 | Score: 1.6419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch   2, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:46:51,471 - INFO - | Epoch   2 | Batch 100/282 | LR 0.00001 | Time 138.80ms | Loss 1.6549 | MSE 0.0000 | CLS 1.6549 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7667\n",
      "2025-02-20 07:47:05,399 - INFO - | Epoch   2 | Batch 200/282 | LR 0.00001 | Time 139.27ms | Loss 1.6525 | MSE 0.0000 | CLS 1.6525 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7833\n",
      "2025-02-20 07:47:22,461 - INFO - ✅ Evaluation Complete | Loss: 1.6647 | Error: 0.8113 | DAB: 0.0000\n",
      "2025-02-20 07:47:22,463 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:47:22,463 - INFO - | End of Epoch   2 | Time: 45.22s | Validation Loss/MSE: 1.6647 | Error Rate: 0.8113\n",
      "2025-02-20 07:47:22,464 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch   3, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:47:36,903 - INFO - | Epoch   3 | Batch 100/282 | LR 0.00001 | Time 141.01ms | Loss 1.6507 | MSE 0.0000 | CLS 1.6507 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7733\n",
      "2025-02-20 07:47:50,859 - INFO - | Epoch   3 | Batch 200/282 | LR 0.00001 | Time 139.55ms | Loss 1.6227 | MSE 0.0000 | CLS 1.6227 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7667\n",
      "2025-02-20 07:48:07,898 - INFO - ✅ Evaluation Complete | Loss: 1.6202 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 07:48:07,900 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:48:07,900 - INFO - | End of Epoch   3 | Time: 45.43s | Validation Loss/MSE: 1.6202 | Error Rate: 0.7972\n",
      "2025-02-20 07:48:07,901 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:48:07,920 - INFO - ✅ New Best Model Saved at Epoch 3 | Score: 1.6202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch   4, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:48:22,353 - INFO - | Epoch   4 | Batch 100/282 | LR 0.00001 | Time 140.96ms | Loss 1.6368 | MSE 0.0000 | CLS 1.6368 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7900\n",
      "2025-02-20 07:48:36,132 - INFO - | Epoch   4 | Batch 200/282 | LR 0.00001 | Time 137.78ms | Loss 1.6141 | MSE 0.0000 | CLS 1.6141 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7400\n",
      "2025-02-20 07:48:53,039 - INFO - ✅ Evaluation Complete | Loss: 1.6195 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 07:48:53,041 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:48:53,042 - INFO - | End of Epoch   4 | Time: 45.12s | Validation Loss/MSE: 1.6195 | Error Rate: 0.7972\n",
      "2025-02-20 07:48:53,042 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:48:53,062 - INFO - ✅ New Best Model Saved at Epoch 4 | Score: 1.6195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch   5, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:49:07,477 - INFO - | Epoch   5 | Batch 100/282 | LR 0.00001 | Time 140.76ms | Loss 1.6411 | MSE 0.0000 | CLS 1.6411 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7733\n",
      "2025-02-20 07:49:21,263 - INFO - | Epoch   5 | Batch 200/282 | LR 0.00001 | Time 137.85ms | Loss 1.6352 | MSE 0.0000 | CLS 1.6352 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.8133\n",
      "2025-02-20 07:49:38,148 - INFO - ✅ Evaluation Complete | Loss: 1.6179 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 07:49:38,150 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:49:38,151 - INFO - | End of Epoch   5 | Time: 45.09s | Validation Loss/MSE: 1.6179 | Error Rate: 0.7972\n",
      "2025-02-20 07:49:38,151 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:49:38,171 - INFO - ✅ New Best Model Saved at Epoch 5 | Score: 1.6179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch   6, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:49:52,453 - INFO - | Epoch   6 | Batch 100/282 | LR 0.00001 | Time 139.40ms | Loss 1.6360 | MSE 0.0000 | CLS 1.6360 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7800\n",
      "2025-02-20 07:50:06,460 - INFO - | Epoch   6 | Batch 200/282 | LR 0.00001 | Time 140.06ms | Loss 1.6251 | MSE 0.0000 | CLS 1.6251 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7633\n",
      "2025-02-20 07:50:23,386 - INFO - ✅ Evaluation Complete | Loss: 1.6459 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 07:50:23,388 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:50:23,388 - INFO - | End of Epoch   6 | Time: 45.22s | Validation Loss/MSE: 1.6459 | Error Rate: 0.7972\n",
      "2025-02-20 07:50:23,389 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch   7, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:50:37,672 - INFO - | Epoch   7 | Batch 100/282 | LR 0.00001 | Time 139.42ms | Loss 1.6387 | MSE 0.0000 | CLS 1.6387 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.8000\n",
      "2025-02-20 07:50:51,657 - INFO - | Epoch   7 | Batch 200/282 | LR 0.00001 | Time 139.84ms | Loss 1.6100 | MSE 0.0000 | CLS 1.6100 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7700\n",
      "2025-02-20 07:51:08,588 - INFO - ✅ Evaluation Complete | Loss: 1.6322 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 07:51:08,590 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:51:08,591 - INFO - | End of Epoch   7 | Time: 45.20s | Validation Loss/MSE: 1.6322 | Error Rate: 0.7972\n",
      "2025-02-20 07:51:08,591 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch   8, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:51:22,889 - INFO - | Epoch   8 | Batch 100/282 | LR 0.00001 | Time 139.51ms | Loss 1.6333 | MSE 0.0000 | CLS 1.6333 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7933\n",
      "2025-02-20 07:51:36,871 - INFO - | Epoch   8 | Batch 200/282 | LR 0.00001 | Time 139.81ms | Loss 1.6242 | MSE 0.0000 | CLS 1.6242 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7667\n",
      "2025-02-20 07:51:53,804 - INFO - ✅ Evaluation Complete | Loss: 1.6303 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 07:51:53,806 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:51:53,807 - INFO - | End of Epoch   8 | Time: 45.21s | Validation Loss/MSE: 1.6303 | Error Rate: 0.7972\n",
      "2025-02-20 07:51:53,808 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch   9, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:52:08,073 - INFO - | Epoch   9 | Batch 100/282 | LR 0.00001 | Time 139.15ms | Loss 1.6320 | MSE 0.0000 | CLS 1.6320 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7967\n",
      "2025-02-20 07:52:22,039 - INFO - | Epoch   9 | Batch 200/282 | LR 0.00001 | Time 139.65ms | Loss 1.6190 | MSE 0.0000 | CLS 1.6190 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7400\n",
      "2025-02-20 07:52:38,960 - INFO - ✅ Evaluation Complete | Loss: 1.6338 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 07:52:38,962 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:52:38,963 - INFO - | End of Epoch   9 | Time: 45.15s | Validation Loss/MSE: 1.6338 | Error Rate: 0.7972\n",
      "2025-02-20 07:52:38,964 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  10, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:52:53,193 - INFO - | Epoch  10 | Batch 100/282 | LR 0.00001 | Time 138.89ms | Loss 1.6459 | MSE 0.0000 | CLS 1.6459 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.8167\n",
      "2025-02-20 07:53:07,181 - INFO - | Epoch  10 | Batch 200/282 | LR 0.00001 | Time 139.87ms | Loss 1.6148 | MSE 0.0000 | CLS 1.6148 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7800\n",
      "2025-02-20 07:53:24,112 - INFO - ✅ Evaluation Complete | Loss: 1.6219 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 07:53:24,114 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:53:24,114 - INFO - | End of Epoch  10 | Time: 45.15s | Validation Loss/MSE: 1.6219 | Error Rate: 0.7972\n",
      "2025-02-20 07:53:24,115 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  11, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:53:38,403 - INFO - | Epoch  11 | Batch 100/282 | LR 0.00001 | Time 139.48ms | Loss 1.6054 | MSE 0.0000 | CLS 1.6054 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7167\n",
      "2025-02-20 07:53:52,216 - INFO - | Epoch  11 | Batch 200/282 | LR 0.00001 | Time 138.11ms | Loss 1.6201 | MSE 0.0000 | CLS 1.6201 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.8267\n",
      "2025-02-20 07:54:09,336 - INFO - ✅ Evaluation Complete | Loss: 1.6056 | Error: 0.7642 | DAB: 0.0000\n",
      "2025-02-20 07:54:09,338 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:54:09,338 - INFO - | End of Epoch  11 | Time: 45.22s | Validation Loss/MSE: 1.6056 | Error Rate: 0.7642\n",
      "2025-02-20 07:54:09,339 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:54:09,358 - INFO - ✅ New Best Model Saved at Epoch 11 | Score: 1.6056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  12, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:54:23,639 - INFO - | Epoch  12 | Batch 100/282 | LR 0.00001 | Time 139.39ms | Loss 1.6287 | MSE 0.0000 | CLS 1.6287 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7500\n",
      "2025-02-20 07:54:37,621 - INFO - | Epoch  12 | Batch 200/282 | LR 0.00001 | Time 139.82ms | Loss 1.6250 | MSE 0.0000 | CLS 1.6250 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7800\n",
      "2025-02-20 07:54:54,789 - INFO - ✅ Evaluation Complete | Loss: 1.6242 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 07:54:54,791 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:54:54,791 - INFO - | End of Epoch  12 | Time: 45.43s | Validation Loss/MSE: 1.6242 | Error Rate: 0.7972\n",
      "2025-02-20 07:54:54,792 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  13, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:55:09,074 - INFO - | Epoch  13 | Batch 100/282 | LR 0.00001 | Time 139.39ms | Loss 1.6300 | MSE 0.0000 | CLS 1.6300 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7533\n",
      "2025-02-20 07:55:22,870 - INFO - | Epoch  13 | Batch 200/282 | LR 0.00001 | Time 137.95ms | Loss 1.6207 | MSE 0.0000 | CLS 1.6207 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7833\n",
      "2025-02-20 07:55:39,926 - INFO - ✅ Evaluation Complete | Loss: 1.6287 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 07:55:39,928 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:55:39,929 - INFO - | End of Epoch  13 | Time: 45.14s | Validation Loss/MSE: 1.6287 | Error Rate: 0.7972\n",
      "2025-02-20 07:55:39,929 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  14, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:55:54,388 - INFO - | Epoch  14 | Batch 100/282 | LR 0.00001 | Time 141.10ms | Loss 1.6292 | MSE 0.0000 | CLS 1.6292 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7800\n",
      "2025-02-20 07:56:08,340 - INFO - | Epoch  14 | Batch 200/282 | LR 0.00001 | Time 139.51ms | Loss 1.6009 | MSE 0.0000 | CLS 1.6009 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7433\n",
      "2025-02-20 07:56:25,529 - INFO - ✅ Evaluation Complete | Loss: 1.6308 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 07:56:25,530 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:56:25,531 - INFO - | End of Epoch  14 | Time: 45.60s | Validation Loss/MSE: 1.6308 | Error Rate: 0.7972\n",
      "2025-02-20 07:56:25,532 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  15, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:56:39,800 - INFO - | Epoch  15 | Batch 100/282 | LR 0.00000 | Time 139.25ms | Loss 1.6328 | MSE 0.0000 | CLS 1.6328 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.8033\n",
      "2025-02-20 07:56:53,911 - INFO - | Epoch  15 | Batch 200/282 | LR 0.00000 | Time 141.11ms | Loss 1.6024 | MSE 0.0000 | CLS 1.6024 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7333\n",
      "2025-02-20 07:57:10,867 - INFO - ✅ Evaluation Complete | Loss: 1.6323 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 07:57:10,869 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:57:10,870 - INFO - | End of Epoch  15 | Time: 45.34s | Validation Loss/MSE: 1.6323 | Error Rate: 0.7972\n",
      "2025-02-20 07:57:10,870 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  16, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:57:25,310 - INFO - | Epoch  16 | Batch 100/282 | LR 0.00000 | Time 141.00ms | Loss 1.6173 | MSE 0.0000 | CLS 1.6173 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7600\n",
      "2025-02-20 07:57:39,106 - INFO - | Epoch  16 | Batch 200/282 | LR 0.00000 | Time 137.95ms | Loss 1.6171 | MSE 0.0000 | CLS 1.6171 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7767\n",
      "2025-02-20 07:57:56,006 - INFO - ✅ Evaluation Complete | Loss: 1.6201 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 07:57:56,008 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:57:56,008 - INFO - | End of Epoch  16 | Time: 45.14s | Validation Loss/MSE: 1.6201 | Error Rate: 0.7972\n",
      "2025-02-20 07:57:56,009 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  17, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:58:10,456 - INFO - | Epoch  17 | Batch 100/282 | LR 0.00000 | Time 141.03ms | Loss 1.6287 | MSE 0.0000 | CLS 1.6287 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7500\n",
      "2025-02-20 07:58:24,258 - INFO - | Epoch  17 | Batch 200/282 | LR 0.00000 | Time 138.01ms | Loss 1.5986 | MSE 0.0000 | CLS 1.5986 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7300\n",
      "2025-02-20 07:58:41,186 - INFO - ✅ Evaluation Complete | Loss: 1.6325 | Error: 0.8113 | DAB: 0.0000\n",
      "2025-02-20 07:58:41,188 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:58:41,189 - INFO - | End of Epoch  17 | Time: 45.18s | Validation Loss/MSE: 1.6325 | Error Rate: 0.8113\n",
      "2025-02-20 07:58:41,190 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  18, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:58:55,636 - INFO - | Epoch  18 | Batch 100/282 | LR 0.00000 | Time 140.97ms | Loss 1.6149 | MSE 0.0000 | CLS 1.6149 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7733\n",
      "2025-02-20 07:59:09,425 - INFO - | Epoch  18 | Batch 200/282 | LR 0.00000 | Time 137.88ms | Loss 1.6101 | MSE 0.0000 | CLS 1.6101 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7500\n",
      "2025-02-20 07:59:26,341 - INFO - ✅ Evaluation Complete | Loss: 1.6144 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 07:59:26,343 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 07:59:26,343 - INFO - | End of Epoch  18 | Time: 45.15s | Validation Loss/MSE: 1.6144 | Error Rate: 0.7972\n",
      "2025-02-20 07:59:26,344 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  19, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 07:59:40,808 - INFO - | Epoch  19 | Batch 100/282 | LR 0.00000 | Time 141.17ms | Loss 1.6196 | MSE 0.0000 | CLS 1.6196 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7767\n",
      "2025-02-20 07:59:54,623 - INFO - | Epoch  19 | Batch 200/282 | LR 0.00000 | Time 138.14ms | Loss 1.6083 | MSE 0.0000 | CLS 1.6083 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7433\n",
      "2025-02-20 08:00:11,558 - INFO - ✅ Evaluation Complete | Loss: 1.6252 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:00:11,560 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:00:11,560 - INFO - | End of Epoch  19 | Time: 45.21s | Validation Loss/MSE: 1.6252 | Error Rate: 0.7972\n",
      "2025-02-20 08:00:11,561 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  20, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:00:25,991 - INFO - | Epoch  20 | Batch 100/282 | LR 0.00000 | Time 140.90ms | Loss 1.6278 | MSE 0.0000 | CLS 1.6278 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7967\n",
      "2025-02-20 08:00:39,772 - INFO - | Epoch  20 | Batch 200/282 | LR 0.00000 | Time 137.80ms | Loss 1.6144 | MSE 0.0000 | CLS 1.6144 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7767\n",
      "2025-02-20 08:00:56,987 - INFO - ✅ Evaluation Complete | Loss: 1.6218 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:00:56,989 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:00:56,989 - INFO - | End of Epoch  20 | Time: 45.43s | Validation Loss/MSE: 1.6218 | Error Rate: 0.7972\n",
      "2025-02-20 08:00:56,990 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  21, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:01:11,401 - INFO - | Epoch  21 | Batch 100/282 | LR 0.00000 | Time 140.67ms | Loss 1.6377 | MSE 0.0000 | CLS 1.6377 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.8100\n",
      "2025-02-20 08:01:25,186 - INFO - | Epoch  21 | Batch 200/282 | LR 0.00000 | Time 137.84ms | Loss 1.6020 | MSE 0.0000 | CLS 1.6020 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7533\n",
      "2025-02-20 08:01:42,128 - INFO - ✅ Evaluation Complete | Loss: 1.6265 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:01:42,130 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:01:42,130 - INFO - | End of Epoch  21 | Time: 45.14s | Validation Loss/MSE: 1.6265 | Error Rate: 0.7972\n",
      "2025-02-20 08:01:42,131 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  22, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:01:56,604 - INFO - | Epoch  22 | Batch 100/282 | LR 0.00000 | Time 141.30ms | Loss 1.6237 | MSE 0.0000 | CLS 1.6237 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7533\n",
      "2025-02-20 08:02:10,407 - INFO - | Epoch  22 | Batch 200/282 | LR 0.00000 | Time 138.02ms | Loss 1.5865 | MSE 0.0000 | CLS 1.5865 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7567\n",
      "2025-02-20 08:02:27,331 - INFO - ✅ Evaluation Complete | Loss: 1.6256 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:02:27,334 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:02:27,335 - INFO - | End of Epoch  22 | Time: 45.20s | Validation Loss/MSE: 1.6256 | Error Rate: 0.7972\n",
      "2025-02-20 08:02:27,335 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  23, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:02:41,778 - INFO - | Epoch  23 | Batch 100/282 | LR 0.00000 | Time 140.96ms | Loss 1.6174 | MSE 0.0000 | CLS 1.6174 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7533\n",
      "2025-02-20 08:02:55,566 - INFO - | Epoch  23 | Batch 200/282 | LR 0.00000 | Time 137.86ms | Loss 1.6133 | MSE 0.0000 | CLS 1.6133 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7800\n",
      "2025-02-20 08:03:12,508 - INFO - ✅ Evaluation Complete | Loss: 1.6254 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:03:12,510 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:03:12,511 - INFO - | End of Epoch  23 | Time: 45.17s | Validation Loss/MSE: 1.6254 | Error Rate: 0.7972\n",
      "2025-02-20 08:03:12,512 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  24, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:03:26,951 - INFO - | Epoch  24 | Batch 100/282 | LR 0.00000 | Time 140.93ms | Loss 1.6210 | MSE 0.0000 | CLS 1.6210 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7533\n",
      "2025-02-20 08:03:40,730 - INFO - | Epoch  24 | Batch 200/282 | LR 0.00000 | Time 137.78ms | Loss 1.6137 | MSE 0.0000 | CLS 1.6137 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7533\n",
      "2025-02-20 08:03:57,641 - INFO - ✅ Evaluation Complete | Loss: 1.6237 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:03:57,643 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:03:57,644 - INFO - | End of Epoch  24 | Time: 45.13s | Validation Loss/MSE: 1.6237 | Error Rate: 0.7972\n",
      "2025-02-20 08:03:57,645 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  25, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:04:12,068 - INFO - | Epoch  25 | Batch 100/282 | LR 0.00000 | Time 140.83ms | Loss 1.6112 | MSE 0.0000 | CLS 1.6112 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7600\n",
      "2025-02-20 08:04:25,832 - INFO - | Epoch  25 | Batch 200/282 | LR 0.00000 | Time 137.63ms | Loss 1.6290 | MSE 0.0000 | CLS 1.6290 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7667\n",
      "2025-02-20 08:04:42,732 - INFO - ✅ Evaluation Complete | Loss: 1.6233 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:04:42,734 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:04:42,735 - INFO - | End of Epoch  25 | Time: 45.09s | Validation Loss/MSE: 1.6233 | Error Rate: 0.7972\n",
      "2025-02-20 08:04:42,735 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  26, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:04:57,173 - INFO - | Epoch  26 | Batch 100/282 | LR 0.00000 | Time 140.86ms | Loss 1.6216 | MSE 0.0000 | CLS 1.6216 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7533\n",
      "2025-02-20 08:05:10,942 - INFO - | Epoch  26 | Batch 200/282 | LR 0.00000 | Time 137.68ms | Loss 1.6076 | MSE 0.0000 | CLS 1.6076 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7700\n",
      "2025-02-20 08:05:28,115 - INFO - ✅ Evaluation Complete | Loss: 1.6270 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:05:28,117 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:05:28,118 - INFO - | End of Epoch  26 | Time: 45.38s | Validation Loss/MSE: 1.6270 | Error Rate: 0.7972\n",
      "2025-02-20 08:05:28,119 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  27, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:05:42,365 - INFO - | Epoch  27 | Batch 100/282 | LR 0.00000 | Time 139.04ms | Loss 1.6282 | MSE 0.0000 | CLS 1.6282 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7567\n",
      "2025-02-20 08:05:56,297 - INFO - | Epoch  27 | Batch 200/282 | LR 0.00000 | Time 139.31ms | Loss 1.6032 | MSE 0.0000 | CLS 1.6032 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7500\n",
      "2025-02-20 08:06:13,346 - INFO - ✅ Evaluation Complete | Loss: 1.6303 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:06:13,347 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:06:13,348 - INFO - | End of Epoch  27 | Time: 45.23s | Validation Loss/MSE: 1.6303 | Error Rate: 0.7972\n",
      "2025-02-20 08:06:13,349 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  28, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:06:27,762 - INFO - | Epoch  28 | Batch 100/282 | LR 0.00000 | Time 140.66ms | Loss 1.6142 | MSE 0.0000 | CLS 1.6142 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7933\n",
      "2025-02-20 08:06:41,536 - INFO - | Epoch  28 | Batch 200/282 | LR 0.00000 | Time 137.73ms | Loss 1.5974 | MSE 0.0000 | CLS 1.5974 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7367\n",
      "2025-02-20 08:06:58,432 - INFO - ✅ Evaluation Complete | Loss: 1.6212 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:06:58,434 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:06:58,435 - INFO - | End of Epoch  28 | Time: 45.09s | Validation Loss/MSE: 1.6212 | Error Rate: 0.7972\n",
      "2025-02-20 08:06:58,436 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  29, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:07:12,857 - INFO - | Epoch  29 | Batch 100/282 | LR 0.00000 | Time 140.66ms | Loss 1.6310 | MSE 0.0000 | CLS 1.6310 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7833\n",
      "2025-02-20 08:07:26,606 - INFO - | Epoch  29 | Batch 200/282 | LR 0.00000 | Time 137.48ms | Loss 1.5866 | MSE 0.0000 | CLS 1.5866 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7200\n",
      "2025-02-20 08:07:43,499 - INFO - ✅ Evaluation Complete | Loss: 1.6100 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:07:43,501 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:07:43,501 - INFO - | End of Epoch  29 | Time: 45.06s | Validation Loss/MSE: 1.6100 | Error Rate: 0.7972\n",
      "2025-02-20 08:07:43,501 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  30, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:07:57,887 - INFO - | Epoch  30 | Batch 100/282 | LR 0.00000 | Time 140.40ms | Loss 1.6312 | MSE 0.0000 | CLS 1.6312 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7467\n",
      "2025-02-20 08:08:11,633 - INFO - | Epoch  30 | Batch 200/282 | LR 0.00000 | Time 137.46ms | Loss 1.6031 | MSE 0.0000 | CLS 1.6031 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7667\n",
      "2025-02-20 08:08:28,500 - INFO - ✅ Evaluation Complete | Loss: 1.6174 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:08:28,502 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:08:28,503 - INFO - | End of Epoch  30 | Time: 45.00s | Validation Loss/MSE: 1.6174 | Error Rate: 0.7972\n",
      "2025-02-20 08:08:28,504 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  31, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:08:42,948 - INFO - | Epoch  31 | Batch 100/282 | LR 0.00000 | Time 140.99ms | Loss 1.6174 | MSE 0.0000 | CLS 1.6174 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7433\n",
      "2025-02-20 08:08:56,738 - INFO - | Epoch  31 | Batch 200/282 | LR 0.00000 | Time 137.89ms | Loss 1.6026 | MSE 0.0000 | CLS 1.6026 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7733\n",
      "2025-02-20 08:09:13,675 - INFO - ✅ Evaluation Complete | Loss: 1.6230 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:09:13,677 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:09:13,677 - INFO - | End of Epoch  31 | Time: 45.17s | Validation Loss/MSE: 1.6230 | Error Rate: 0.7972\n",
      "2025-02-20 08:09:13,678 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  32, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:09:28,127 - INFO - | Epoch  32 | Batch 100/282 | LR 0.00000 | Time 141.03ms | Loss 1.6223 | MSE 0.0000 | CLS 1.6223 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7467\n",
      "2025-02-20 08:09:41,930 - INFO - | Epoch  32 | Batch 200/282 | LR 0.00000 | Time 138.02ms | Loss 1.5984 | MSE 0.0000 | CLS 1.5984 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7533\n",
      "2025-02-20 08:09:58,870 - INFO - ✅ Evaluation Complete | Loss: 1.6177 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:09:58,872 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:09:58,873 - INFO - | End of Epoch  32 | Time: 45.19s | Validation Loss/MSE: 1.6177 | Error Rate: 0.7972\n",
      "2025-02-20 08:09:58,874 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  33, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:10:13,335 - INFO - | Epoch  33 | Batch 100/282 | LR 0.00000 | Time 141.20ms | Loss 1.6034 | MSE 0.0000 | CLS 1.6034 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7100\n",
      "2025-02-20 08:10:27,144 - INFO - | Epoch  33 | Batch 200/282 | LR 0.00000 | Time 138.09ms | Loss 1.6170 | MSE 0.0000 | CLS 1.6170 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7700\n",
      "2025-02-20 08:10:44,082 - INFO - ✅ Evaluation Complete | Loss: 1.6121 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:10:44,085 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:10:44,085 - INFO - | End of Epoch  33 | Time: 45.21s | Validation Loss/MSE: 1.6121 | Error Rate: 0.7972\n",
      "2025-02-20 08:10:44,086 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  34, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:10:58,542 - INFO - | Epoch  34 | Batch 100/282 | LR 0.00000 | Time 141.11ms | Loss 1.6234 | MSE 0.0000 | CLS 1.6234 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7867\n",
      "2025-02-20 08:11:12,341 - INFO - | Epoch  34 | Batch 200/282 | LR 0.00000 | Time 137.98ms | Loss 1.6048 | MSE 0.0000 | CLS 1.6048 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7600\n",
      "2025-02-20 08:11:29,295 - INFO - ✅ Evaluation Complete | Loss: 1.6270 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:11:29,297 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:11:29,298 - INFO - | End of Epoch  34 | Time: 45.21s | Validation Loss/MSE: 1.6270 | Error Rate: 0.7972\n",
      "2025-02-20 08:11:29,299 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  35, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:11:43,775 - INFO - | Epoch  35 | Batch 100/282 | LR 0.00000 | Time 141.22ms | Loss 1.6285 | MSE 0.0000 | CLS 1.6285 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7767\n",
      "2025-02-20 08:11:57,582 - INFO - | Epoch  35 | Batch 200/282 | LR 0.00000 | Time 138.05ms | Loss 1.6123 | MSE 0.0000 | CLS 1.6123 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7600\n",
      "2025-02-20 08:12:14,511 - INFO - ✅ Evaluation Complete | Loss: 1.6276 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:12:14,513 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:12:14,514 - INFO - | End of Epoch  35 | Time: 45.21s | Validation Loss/MSE: 1.6276 | Error Rate: 0.7972\n",
      "2025-02-20 08:12:14,514 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  36, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:12:28,970 - INFO - | Epoch  36 | Batch 100/282 | LR 0.00000 | Time 140.99ms | Loss 1.6212 | MSE 0.0000 | CLS 1.6212 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7767\n",
      "2025-02-20 08:12:42,770 - INFO - | Epoch  36 | Batch 200/282 | LR 0.00000 | Time 137.99ms | Loss 1.6101 | MSE 0.0000 | CLS 1.6101 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7567\n",
      "2025-02-20 08:12:59,676 - INFO - ✅ Evaluation Complete | Loss: 1.6217 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:12:59,678 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:12:59,679 - INFO - | End of Epoch  36 | Time: 45.16s | Validation Loss/MSE: 1.6217 | Error Rate: 0.7972\n",
      "2025-02-20 08:12:59,679 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  37, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:13:14,108 - INFO - | Epoch  37 | Batch 100/282 | LR 0.00000 | Time 140.76ms | Loss 1.6166 | MSE 0.0000 | CLS 1.6166 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7500\n",
      "2025-02-20 08:13:27,897 - INFO - | Epoch  37 | Batch 200/282 | LR 0.00000 | Time 137.89ms | Loss 1.5991 | MSE 0.0000 | CLS 1.5991 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7400\n",
      "2025-02-20 08:13:44,835 - INFO - ✅ Evaluation Complete | Loss: 1.6216 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:13:44,837 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:13:44,838 - INFO - | End of Epoch  37 | Time: 45.16s | Validation Loss/MSE: 1.6216 | Error Rate: 0.7972\n",
      "2025-02-20 08:13:44,838 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  38, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:13:59,314 - INFO - | Epoch  38 | Batch 100/282 | LR 0.00000 | Time 141.24ms | Loss 1.6226 | MSE 0.0000 | CLS 1.6226 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7867\n",
      "2025-02-20 08:14:13,120 - INFO - | Epoch  38 | Batch 200/282 | LR 0.00000 | Time 138.05ms | Loss 1.5837 | MSE 0.0000 | CLS 1.5837 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7033\n",
      "2025-02-20 08:14:30,055 - INFO - ✅ Evaluation Complete | Loss: 1.6159 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:14:30,057 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:14:30,058 - INFO - | End of Epoch  38 | Time: 45.22s | Validation Loss/MSE: 1.6159 | Error Rate: 0.7972\n",
      "2025-02-20 08:14:30,059 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  39, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:14:44,489 - INFO - | Epoch  39 | Batch 100/282 | LR 0.00000 | Time 140.87ms | Loss 1.6325 | MSE 0.0000 | CLS 1.6325 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7967\n",
      "2025-02-20 08:14:58,268 - INFO - | Epoch  39 | Batch 200/282 | LR 0.00000 | Time 137.78ms | Loss 1.5916 | MSE 0.0000 | CLS 1.5916 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7600\n",
      "2025-02-20 08:15:15,448 - INFO - ✅ Evaluation Complete | Loss: 1.6238 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:15:15,449 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:15:15,450 - INFO - | End of Epoch  39 | Time: 45.39s | Validation Loss/MSE: 1.6238 | Error Rate: 0.7972\n",
      "2025-02-20 08:15:15,451 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  40, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:15:29,695 - INFO - | Epoch  40 | Batch 100/282 | LR 0.00000 | Time 138.99ms | Loss 1.6268 | MSE 0.0000 | CLS 1.6268 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7633\n",
      "2025-02-20 08:15:43,628 - INFO - | Epoch  40 | Batch 200/282 | LR 0.00000 | Time 139.32ms | Loss 1.6016 | MSE 0.0000 | CLS 1.6016 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7567\n",
      "2025-02-20 08:16:00,682 - INFO - ✅ Evaluation Complete | Loss: 1.6235 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:16:00,684 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:16:00,685 - INFO - | End of Epoch  40 | Time: 45.23s | Validation Loss/MSE: 1.6235 | Error Rate: 0.7972\n",
      "2025-02-20 08:16:00,685 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  41, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:16:15,137 - INFO - | Epoch  41 | Batch 100/282 | LR 0.00000 | Time 141.02ms | Loss 1.6316 | MSE 0.0000 | CLS 1.6316 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7700\n",
      "2025-02-20 08:16:28,924 - INFO - | Epoch  41 | Batch 200/282 | LR 0.00000 | Time 137.86ms | Loss 1.5943 | MSE 0.0000 | CLS 1.5943 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7700\n",
      "2025-02-20 08:16:45,851 - INFO - ✅ Evaluation Complete | Loss: 1.6234 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:16:45,853 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:16:45,854 - INFO - | End of Epoch  41 | Time: 45.17s | Validation Loss/MSE: 1.6234 | Error Rate: 0.7972\n",
      "2025-02-20 08:16:45,854 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  42, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:17:00,287 - INFO - | Epoch  42 | Batch 100/282 | LR 0.00000 | Time 140.87ms | Loss 1.6213 | MSE 0.0000 | CLS 1.6213 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7533\n",
      "2025-02-20 08:17:14,043 - INFO - | Epoch  42 | Batch 200/282 | LR 0.00000 | Time 137.56ms | Loss 1.6170 | MSE 0.0000 | CLS 1.6170 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7900\n",
      "2025-02-20 08:17:30,959 - INFO - ✅ Evaluation Complete | Loss: 1.6254 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:17:30,961 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:17:30,961 - INFO - | End of Epoch  42 | Time: 45.11s | Validation Loss/MSE: 1.6254 | Error Rate: 0.7972\n",
      "2025-02-20 08:17:30,962 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  43, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:17:45,406 - INFO - | Epoch  43 | Batch 100/282 | LR 0.00000 | Time 140.97ms | Loss 1.6151 | MSE 0.0000 | CLS 1.6151 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7800\n",
      "2025-02-20 08:17:59,173 - INFO - | Epoch  43 | Batch 200/282 | LR 0.00000 | Time 137.66ms | Loss 1.6064 | MSE 0.0000 | CLS 1.6064 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7333\n",
      "2025-02-20 08:18:16,059 - INFO - ✅ Evaluation Complete | Loss: 1.6211 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:18:16,061 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:18:16,062 - INFO - | End of Epoch  43 | Time: 45.10s | Validation Loss/MSE: 1.6211 | Error Rate: 0.7972\n",
      "2025-02-20 08:18:16,062 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  44, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:18:30,491 - INFO - | Epoch  44 | Batch 100/282 | LR 0.00000 | Time 140.89ms | Loss 1.6203 | MSE 0.0000 | CLS 1.6203 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7600\n",
      "2025-02-20 08:18:44,256 - INFO - | Epoch  44 | Batch 200/282 | LR 0.00000 | Time 137.64ms | Loss 1.5949 | MSE 0.0000 | CLS 1.5949 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7467\n",
      "2025-02-20 08:19:01,145 - INFO - ✅ Evaluation Complete | Loss: 1.6188 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:19:01,147 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:19:01,148 - INFO - | End of Epoch  44 | Time: 45.08s | Validation Loss/MSE: 1.6188 | Error Rate: 0.7972\n",
      "2025-02-20 08:19:01,148 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  45, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:19:15,570 - INFO - | Epoch  45 | Batch 100/282 | LR 0.00000 | Time 140.74ms | Loss 1.6132 | MSE 0.0000 | CLS 1.6132 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7733\n",
      "2025-02-20 08:19:29,329 - INFO - | Epoch  45 | Batch 200/282 | LR 0.00000 | Time 137.58ms | Loss 1.5953 | MSE 0.0000 | CLS 1.5953 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7367\n",
      "2025-02-20 08:19:46,515 - INFO - ✅ Evaluation Complete | Loss: 1.6183 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:19:46,517 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:19:46,517 - INFO - | End of Epoch  45 | Time: 45.37s | Validation Loss/MSE: 1.6183 | Error Rate: 0.7972\n",
      "2025-02-20 08:19:46,518 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  46, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:20:00,920 - INFO - | Epoch  46 | Batch 100/282 | LR 0.00000 | Time 140.57ms | Loss 1.6189 | MSE 0.0000 | CLS 1.6189 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7633\n",
      "2025-02-20 08:20:14,698 - INFO - | Epoch  46 | Batch 200/282 | LR 0.00000 | Time 137.77ms | Loss 1.5931 | MSE 0.0000 | CLS 1.5931 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7267\n",
      "2025-02-20 08:20:31,610 - INFO - ✅ Evaluation Complete | Loss: 1.6207 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:20:31,612 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:20:31,612 - INFO - | End of Epoch  46 | Time: 45.09s | Validation Loss/MSE: 1.6207 | Error Rate: 0.7972\n",
      "2025-02-20 08:20:31,613 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  47, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:20:46,038 - INFO - | Epoch  47 | Batch 100/282 | LR 0.00000 | Time 140.78ms | Loss 1.6059 | MSE 0.0000 | CLS 1.6059 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7400\n",
      "2025-02-20 08:20:59,808 - INFO - | Epoch  47 | Batch 200/282 | LR 0.00000 | Time 137.69ms | Loss 1.6013 | MSE 0.0000 | CLS 1.6013 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7567\n",
      "2025-02-20 08:21:16,716 - INFO - ✅ Evaluation Complete | Loss: 1.6197 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:21:16,718 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:21:16,719 - INFO - | End of Epoch  47 | Time: 45.10s | Validation Loss/MSE: 1.6197 | Error Rate: 0.7972\n",
      "2025-02-20 08:21:16,719 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  48, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:21:31,137 - INFO - | Epoch  48 | Batch 100/282 | LR 0.00000 | Time 140.69ms | Loss 1.6133 | MSE 0.0000 | CLS 1.6133 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7467\n",
      "2025-02-20 08:21:44,897 - INFO - | Epoch  48 | Batch 200/282 | LR 0.00000 | Time 137.59ms | Loss 1.6070 | MSE 0.0000 | CLS 1.6070 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7633\n",
      "2025-02-20 08:22:01,805 - INFO - ✅ Evaluation Complete | Loss: 1.6177 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:22:01,807 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:22:01,807 - INFO - | End of Epoch  48 | Time: 45.09s | Validation Loss/MSE: 1.6177 | Error Rate: 0.7972\n",
      "2025-02-20 08:22:01,808 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  49, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:22:16,239 - INFO - | Epoch  49 | Batch 100/282 | LR 0.00000 | Time 140.83ms | Loss 1.6247 | MSE 0.0000 | CLS 1.6247 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7667\n",
      "2025-02-20 08:22:29,979 - INFO - | Epoch  49 | Batch 200/282 | LR 0.00000 | Time 137.39ms | Loss 1.5904 | MSE 0.0000 | CLS 1.5904 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7300\n",
      "2025-02-20 08:22:46,874 - INFO - ✅ Evaluation Complete | Loss: 1.6192 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:22:46,876 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:22:46,877 - INFO - | End of Epoch  49 | Time: 45.07s | Validation Loss/MSE: 1.6192 | Error Rate: 0.7972\n",
      "2025-02-20 08:22:46,877 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total Genes: 23794 | Mapped: 23794 | First 10 IDs: [16625  8892 18555 18552 18549 14169  9123 13965 13453  9070]\n",
      "🔍 `values_tensor` shape before filtering: torch.Size([1058, 23794])\n",
      "✅ `values_tensor` shape after filtering: torch.Size([1058, 23794])\n",
      "🔍 Train values shape: torch.Size([846, 23794]) | Test values shape: torch.Size([212, 23794])\n",
      "🔹 Random masking applied at epoch  50, ratio of masked values in train: 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 08:23:01,271 - INFO - | Epoch  50 | Batch 100/282 | LR 0.00000 | Time 140.47ms | Loss 1.6162 | MSE 0.0000 | CLS 1.6162 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7333\n",
      "2025-02-20 08:23:15,019 - INFO - | Epoch  50 | Batch 200/282 | LR 0.00000 | Time 137.47ms | Loss 1.5895 | MSE 0.0000 | CLS 1.5895 | CCE 0.0000 | MVC 0.0000 | ECS 0.0000 | DAB 0.0000 | ADV_E 0.0000 | ADV_D 0.0000 | NZLP 0.0000 | MVC_NZLP 0.0000 | Error 0.7400\n",
      "2025-02-20 08:23:31,930 - INFO - ✅ Evaluation Complete | Loss: 1.6173 | Error: 0.7972 | DAB: 0.0000\n",
      "2025-02-20 08:23:31,931 - INFO - -----------------------------------------------------------------------------------------\n",
      "2025-02-20 08:23:31,932 - INFO - | End of Epoch  50 | Time: 45.05s | Validation Loss/MSE: 1.6173 | Error Rate: 0.7972\n",
      "2025-02-20 08:23:31,932 - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved at: /data/cellular_aging/results/fine-tuning/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "import scipy.sparse\n",
    "\n",
    "# ✅ Define mask_value and pad_value if not defined\n",
    "mask_value = 0.0\n",
    "pad_value = 0\n",
    "DAB_separate_optim = False  # ✅ Set a default value\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ✅ Generate observation indices and split into train and test\n",
    "obs_index = np.arange(adata_sample.n_obs)\n",
    "train_idx, test_idx = train_test_split(obs_index, test_size=0.2, random_state=42)\n",
    "train_idx = np.array(train_idx, dtype=np.int64)\n",
    "test_idx = np.array(test_idx, dtype=np.int64)\n",
    "\n",
    "# ✅ Define classification criterion\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "\n",
    "# ✅ Define Optimizer Before Training\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr)\n",
    "\n",
    "# ✅ If using a learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "# ✅ Initialize best scores\n",
    "best_val_loss = float(\"inf\")\n",
    "best_avg_bio = 0.0\n",
    "best_model = None\n",
    "\n",
    "# ✅ Define WandB metrics\n",
    "define_wandb_metrics()\n",
    "\n",
    "# ✅ Training Loop\n",
    "for epoch in range(1, config.epochs + 1):    \n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    # ✅ Extract gene symbols and map to vocab indices\n",
    "    filtered_gene_symbols = adata_sample.var[\"gene_symbol\"].tolist()\n",
    "    filtered_gene_ids = np.array(\n",
    "        [vocab.get(gene, vocab.get(\"<pad>\", 0)) for gene in filtered_gene_symbols],\n",
    "        dtype=np.int64,\n",
    "    )\n",
    "\n",
    "    print(f\"🔍 Total Genes: {len(filtered_gene_symbols)} | Mapped: {filtered_gene_ids.shape[0]} | First 10 IDs: {filtered_gene_ids[:10]}\")\n",
    "\n",
    "    # ✅ Select the correct preprocessed data layer\n",
    "    if \"X_binned\" in adata_sample.layers:\n",
    "        data_layer = adata_sample.layers[\"X_binned\"]\n",
    "    elif \"X_normed\" in adata_sample.layers:\n",
    "        data_layer = adata_sample.layers[\"X_normed\"]\n",
    "    elif \"X_log1p\" in adata_sample.layers:\n",
    "        data_layer = adata_sample.layers[\"X_log1p\"]\n",
    "    else:\n",
    "        raise ValueError(\"❌ No valid processed data layer found in `adata_sample`!\")\n",
    "\n",
    "    # ✅ Convert sparse matrix to dense\n",
    "    if issparse(data_layer):\n",
    "        data_layer = data_layer.toarray()\n",
    "\n",
    "    # ✅ Convert to PyTorch tensor and move to GPU\n",
    "    values_tensor = torch.tensor(data_layer, dtype=torch.float32, device=device)\n",
    "\n",
    "    print(f\"🔍 `values_tensor` shape before filtering: {values_tensor.shape}\")\n",
    "\n",
    "    # ✅ Ensure correct number of features\n",
    "    num_sampled_genes = len(filtered_gene_ids)\n",
    "    if values_tensor.shape[1] != num_sampled_genes:\n",
    "        raise ValueError(\n",
    "            f\"❌ Mismatch: `values_tensor` has {values_tensor.shape[1]} features, \"\n",
    "            f\"but `filtered_gene_ids` has {num_sampled_genes} genes. Fix dataset filtering.\"\n",
    "        )\n",
    "    \n",
    "    print(f\"✅ `values_tensor` shape after filtering: {values_tensor.shape}\")\n",
    "\n",
    "    # ✅ Convert gene IDs to tensor and move to GPU\n",
    "    gene_ids_tensor = torch.tensor(filtered_gene_ids, dtype=torch.long, device=device)\n",
    "\n",
    "    # ✅ Convert train/test data and move to GPU\n",
    "    train_data = {\n",
    "        \"gene_ids\": gene_ids_tensor,  # Same mapping for all cells\n",
    "        \"values\": values_tensor[train_idx],\n",
    "        \"target_values\": target_values_tensor[train_idx].to(device, non_blocking=True),\n",
    "        \"batch_labels\": batch_labels_tensor[train_idx].to(device, non_blocking=True),\n",
    "        \"age_labels\": age_labels_tensor[train_idx].to(device, non_blocking=True),\n",
    "    }\n",
    "    test_data = {\n",
    "        \"gene_ids\": gene_ids_tensor,\n",
    "        \"values\": values_tensor[test_idx],\n",
    "        \"target_values\": target_values_tensor[test_idx].to(device, non_blocking=True),\n",
    "        \"batch_labels\": batch_labels_tensor[test_idx].to(device, non_blocking=True),\n",
    "        \"age_labels\": age_labels_tensor[test_idx].to(device, non_blocking=True),\n",
    "    }\n",
    "\n",
    "    print(f\"🔍 Train values shape: {train_data['values'].shape} | Test values shape: {test_data['values'].shape}\")\n",
    "\n",
    "    # ✅ Tokenize train/validation data\n",
    "    tokenized_train = tokenize_and_pad_batch(\n",
    "        train_data[\"values\"].cpu().numpy(),  # Convert back to NumPy only when necessary\n",
    "        gene_ids=filtered_gene_ids.copy(),\n",
    "        max_len=max_seq_len,\n",
    "        vocab=vocab,\n",
    "        pad_token=pad_token,\n",
    "        pad_value=pad_value,\n",
    "        append_cls=True,\n",
    "        include_zero_gene=config.include_zero_gene,\n",
    "    )\n",
    "    tokenized_valid = tokenize_and_pad_batch(\n",
    "        test_data[\"values\"].cpu().numpy(),\n",
    "        gene_ids=filtered_gene_ids.copy(),\n",
    "        max_len=max_seq_len,\n",
    "        vocab=vocab,\n",
    "        pad_token=pad_token,\n",
    "        pad_value=pad_value,\n",
    "        append_cls=True,\n",
    "        include_zero_gene=config.include_zero_gene,\n",
    "    )\n",
    "\n",
    "    # ✅ Prepare data for model input\n",
    "    train_data_pt, valid_data_pt = prepare_data(\n",
    "        tokenized_train, tokenized_valid,\n",
    "        train_batch_labels=train_data[\"batch_labels\"].cpu().numpy(),\n",
    "        valid_batch_labels=test_data[\"batch_labels\"].cpu().numpy(),\n",
    "        train_age_labels=train_data[\"age_labels\"].cpu().numpy(),\n",
    "        valid_age_labels=test_data[\"age_labels\"].cpu().numpy(),\n",
    "        mask_ratio=config.mask_ratio,\n",
    "        mask_value=mask_value,\n",
    "        pad_value=pad_value,\n",
    "        epoch=epoch,\n",
    "        sort_seq_batch=per_seq_batch_sample\n",
    "    )\n",
    "\n",
    "    # ✅ Prepare Data Loaders\n",
    "    train_loader = prepare_dataloader(\n",
    "        train_data_pt,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        intra_domain_shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    valid_loader = prepare_dataloader(\n",
    "        valid_data_pt,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        intra_domain_shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ✅ Initialize GradScaler for mixed precision training if enabled\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=config.amp)\n",
    "\n",
    "    # ✅ Train the model\n",
    "    if config.do_train:\n",
    "        train(model, loader=train_loader, epoch=epoch)\n",
    "\n",
    "    # ✅ Evaluate the model\n",
    "    val_loss, val_err = evaluate(model, loader=valid_loader)\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "\n",
    "    logger.info(\"-\" * 89)\n",
    "    logger.info(\n",
    "        f\"| End of Epoch {epoch:3d} | Time: {elapsed:5.2f}s | \"\n",
    "        f\"Validation Loss/MSE: {val_loss:.4f} | Error Rate: {val_err:.4f}\"\n",
    "    )\n",
    "    logger.info(\"-\" * 89)\n",
    "\n",
    "    # ✅ Track best model based on validation loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_model_epoch = epoch\n",
    "        logger.info(f\"✅ New Best Model Saved at Epoch {epoch} | Score: {best_val_loss:.4f}\")\n",
    "\n",
    "    # ✅ Step the scheduler(s)\n",
    "    scheduler.step()\n",
    "    if DAB_separate_optim:\n",
    "        scheduler_dab.step()\n",
    "    if ADV:\n",
    "        scheduler_D.step()\n",
    "        scheduler_E.step()\n",
    "\n",
    "\n",
    "# ✅ Ensure `save_dir` is defined\n",
    "save_dir = Path(\"/data/cellular_aging/results/fine-tuning\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ✅ Define `best_model_path`\n",
    "best_model_path = save_dir / \"best_model.pt\"\n",
    "\n",
    "# ✅ Handle multi-GPU model saving\n",
    "if isinstance(model, torch.nn.DataParallel):\n",
    "    torch.save(best_model.module.state_dict(), best_model_path)  # Remove DataParallel wrapper\n",
    "else:\n",
    "    torch.save(best_model.state_dict(), best_model_path)\n",
    "\n",
    "print(f\"✅ Best model saved at: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b8030f5-888f-419e-aeed-c57f66f31ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: nn.Module, test_data: Dict[str, torch.Tensor]) -> float:\n",
    "    \"\"\"\n",
    "    Test the model on the test data.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_error = 0.0\n",
    "    total_dab = 0.0\n",
    "    total_num = 0\n",
    "    predictions = []\n",
    "\n",
    "    # Prepare DataLoader for testing\n",
    "    test_loader = DataLoader(\n",
    "        dataset=SeqDataset(test_data),\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=min(len(os.sched_getaffinity(0)), eval_batch_size // 2),\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in test_loader:\n",
    "            input_gene_ids = batch_data[\"gene_ids\"].to(device)\n",
    "            input_values = batch_data[\"values\"].to(device)\n",
    "            target_values = batch_data[\"target_values\"].to(device)\n",
    "            batch_labels = batch_data[\"batch_labels\"].to(device)\n",
    "            age_labels = batch_data[\"age_labels\"].to(device)\n",
    "\n",
    "            src_key_padding_mask = input_gene_ids.eq(vocab[pad_token])\n",
    "            with torch.cuda.amp.autocast(enabled=config.amp):\n",
    "                output_dict = model(\n",
    "                    input_gene_ids,\n",
    "                    input_values,\n",
    "                    src_key_padding_mask=src_key_padding_mask,\n",
    "                    batch_labels=batch_labels if INPUT_BATCH_LABELS or config.DSBN else None,\n",
    "                    CLS=CLS,\n",
    "                    CCE=False,\n",
    "                    MVC=False,\n",
    "                    ECS=False,\n",
    "                    do_sample=do_sample_in_train,\n",
    "                )\n",
    "                output_values = output_dict[\"cls_output\"]\n",
    "                loss = criterion_cls(output_values, age_labels)\n",
    "\n",
    "                if DAB:\n",
    "                    loss_dab = criterion_dab(output_dict[\"dab_output\"], batch_labels)\n",
    "\n",
    "            total_loss += loss.item() * len(input_gene_ids)\n",
    "            accuracy = (output_values.argmax(1) == age_labels).sum().item()\n",
    "            total_error += (1 - accuracy / len(input_gene_ids)) * len(input_gene_ids)\n",
    "            total_dab += loss_dab.item() * len(input_gene_ids) if DAB else 0.0\n",
    "            total_num += len(input_gene_ids)\n",
    "            preds = output_values.argmax(1).cpu().numpy()\n",
    "            predictions.append(preds)\n",
    "\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"test/mse\": total_loss / total_num,\n",
    "            \"test/err\": total_error / total_num,\n",
    "            \"test/dab\": total_dab / total_num,\n",
    "            \"test/sum_mse_dab\": (total_loss + dab_weight * total_dab) / total_num,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return np.concatenate(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333923a-e843-4a00-b864-d93996816dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88fcc51a-014e-46ff-80d7-06e3fff59762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n",
      "Fixed input_gene_ids shape: torch.Size([3, 23794])\n",
      "Fixed input_values shape: torch.Size([3, 23794])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/data/miniconda/envs/myenv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/data/miniconda/envs/myenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/data/miniconda/envs/myenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_88838/2443685756.py\", line 11, in __getitem__\n    return {k: v[idx] for k, v in self.data.items()}\n  File \"/tmp/ipykernel_88838/2443685756.py\", line 11, in <dictcomp>\n    return {k: v[idx] for k, v in self.data.items()}\nIndexError: index 212 is out of bounds for dimension 0 with size 212\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# ✅ Run inference\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 24\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, test_data)\u001b[0m\n\u001b[1;32m     14\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     15\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mSeqDataset(test_data),\n\u001b[1;32m     16\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39meval_batch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_data \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     25\u001b[0m         input_gene_ids \u001b[38;5;241m=\u001b[39m batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgene_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Expected: (batch_size, seq_len)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m         input_values \u001b[38;5;241m=\u001b[39m batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Expected: (batch_size, seq_len)\u001b[39;00m\n",
      "File \u001b[0;32m/data/miniconda/envs/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/data/miniconda/envs/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/miniconda/envs/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/data/miniconda/envs/myenv/lib/python3.10/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/data/miniconda/envs/myenv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/data/miniconda/envs/myenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/data/miniconda/envs/myenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_88838/2443685756.py\", line 11, in __getitem__\n    return {k: v[idx] for k, v in self.data.items()}\n  File \"/tmp/ipykernel_88838/2443685756.py\", line 11, in <dictcomp>\n    return {k: v[idx] for k, v in self.data.items()}\nIndexError: index 212 is out of bounds for dimension 0 with size 212\n"
     ]
    }
   ],
   "source": [
    "# %% Inference\n",
    "def test(model: nn.Module, test_data: Dict[str, torch.Tensor]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform inference on the test dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    # ✅ Ensure model is not wrapped in DataParallel\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model = model.module  \n",
    "\n",
    "    # ✅ Prepare DataLoader for testing\n",
    "    test_loader = DataLoader(\n",
    "        dataset=SeqDataset(test_data),\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=min(len(os.sched_getaffinity(0)), eval_batch_size // 2),\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in test_loader:\n",
    "            input_gene_ids = batch_data[\"gene_ids\"].to(device)  # Expected: (batch_size, seq_len)\n",
    "            input_values = batch_data[\"values\"].to(device)  # Expected: (batch_size, seq_len)\n",
    "\n",
    "            # ✅ Ensure input_gene_ids is correctly expanded\n",
    "            if input_gene_ids.dim() == 1:\n",
    "                input_gene_ids = input_gene_ids.unsqueeze(1).expand(-1, input_values.shape[1])\n",
    "\n",
    "            # ✅ Debugging: Print corrected shapes\n",
    "            print(f\"Fixed input_gene_ids shape: {input_gene_ids.shape}\")  # Should match input_values\n",
    "            print(f\"Fixed input_values shape: {input_values.shape}\")  \n",
    "\n",
    "            # Ensure input shapes are now matching\n",
    "            assert input_gene_ids.shape == input_values.shape, \"Mismatch in input_gene_ids and input_values shape!\"\n",
    "\n",
    "            src_key_padding_mask = input_gene_ids.eq(vocab[pad_token])\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=config.amp):\n",
    "                output_dict = model(\n",
    "                    input_gene_ids,\n",
    "                    input_values,\n",
    "                    src_key_padding_mask=src_key_padding_mask,\n",
    "                    CLS=True,\n",
    "                    CCE=False,\n",
    "                    MVC=False,\n",
    "                    ECS=False,\n",
    "                    do_sample=do_sample_in_train,\n",
    "                )\n",
    "\n",
    "                output_values = output_dict[\"cls_output\"]\n",
    "                batch_preds = output_values.argmax(1).cpu().numpy()\n",
    "                predictions.append(batch_preds)\n",
    "\n",
    "    return np.concatenate(predictions, axis=0)\n",
    "\n",
    "# ✅ Run inference\n",
    "test_predictions = test(best_model, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ddf2c-2249-45bf-a419-ad8299314fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on the test dataset\n",
    "test_predictions, test_labels, test_results = test(best_model, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "129283f1-e359-4e24-9d33-9311107c6f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['gene_ids', 'values', 'target_values', 'batch_labels', 'age_labels'])\n"
     ]
    }
   ],
   "source": [
    "print(type(test_data))  # Check the type of test_data\n",
    "if isinstance(test_data, dict):\n",
    "    print(test_data.keys())  # Print keys if it's a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a093f4b-98e1-4798-97c2-e13b847c6558",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions, labels, results \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m(best_model, adata_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de9656-069d-416a-9746-b3b4b4cc6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata_test_raw,\n",
    "    color=[\"age\", \"predictions\"],\n",
    "    palette=palette_,\n",
    "    show=False,\n",
    ")\n",
    "plt.savefig(save_dir / \"results.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536989f7-ba81-43f3-a677-0a47701e32ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(labels, predictions)\n",
    "sns.heatmap(cm, annot=True, fmt=\".1f\", cmap=\"Blues\")\n",
    "plt.savefig(save_dir / \"confusion_matrix.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c888493f-04c3-45a4-a184-123cae0afe36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610747c-82da-4d55-b3b1-083b3ee57e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf9a7e64-930e-4a57-8546-7c0b12c99d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">azure-snowflake-13</strong> at: <a href='https://wandb.ai/malam007-old-dominion-university/scGPT/runs/5ttspezu' target=\"_blank\">https://wandb.ai/malam007-old-dominion-university/scGPT/runs/5ttspezu</a><br> View project at: <a href='https://wandb.ai/malam007-old-dominion-university/scGPT' target=\"_blank\">https://wandb.ai/malam007-old-dominion-university/scGPT</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/tmp/wandb/run-20250219_232751-5ttspezu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/wandb/run-20250220_003501-1tdianwq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/malam007-old-dominion-university/scGPT/runs/1tdianwq' target=\"_blank\">jumping-deluge-14</a></strong> to <a href='https://wandb.ai/malam007-old-dominion-university/scGPT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/malam007-old-dominion-university/scGPT' target=\"_blank\">https://wandb.ai/malam007-old-dominion-university/scGPT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/malam007-old-dominion-university/scGPT/runs/1tdianwq' target=\"_blank\">https://wandb.ai/malam007-old-dominion-university/scGPT/runs/1tdianwq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 **Final Gene Mapping & Expression Coverage Summary:**\n",
      "🔹 Total Genes Before Vocab Filtering: 36161\n",
      "🔹 Total Genes After Vocab Filtering: 23794\n",
      "🔹 Total Expression Before Vocab Filtering: 2888279552.00\n",
      "🔹 Total Expression After Vocab Filtering: 2841698816.00\n",
      "✅ Gene Coverage After Vocab Filtering: 65.80%\n",
      "✅ Expression Coverage After Vocab Filtering: 98.39%\n",
      "✅ Sampled dataset shape: (1058, 23794)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import wandb\n",
    "from scipy.sparse import issparse, csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import Vocab as VocabPybind\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sys.path.insert(0, \"../\")\n",
    "import scgpt as scg\n",
    "from scgpt.model import TransformerModel, AdversarialDiscriminator\n",
    "from scgpt.tokenizer import tokenize_and_pad_batch, random_mask_value\n",
    "from scgpt.loss import (\n",
    "    masked_mse_loss,\n",
    "    masked_relative_error,\n",
    "    criterion_neg_log_bernoulli,\n",
    ")\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt import SubsetsBatchSampler\n",
    "from scgpt.utils import set_seed, category_str2int, eval_scib_metrics\n",
    "\n",
    "# Ignore warnings\n",
    "sc.set_figure_params(figsize=(6, 6))\n",
    "os.environ[\"KMP_WARNINGS\"] = \"off\"\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ✅ **Hyperparameters and Configurations**\n",
    "hyperparameter_defaults = dict(\n",
    "    seed=0,\n",
    "    dataset_name=\"AIDA1_sample\",\n",
    "    do_train=True,\n",
    "    load_model=\"/data/cellular_aging/references/scGPT_human_pretrained_model\",\n",
    "    mask_ratio=0.15,\n",
    "    epochs=5,\n",
    "    n_bins=51,\n",
    "    MVC=False,  # Masked value prediction for cell embedding\n",
    "    ecs_thres=0.0,  # Elastic cell similarity objective, 0.0 to 1.0, 0.0 to disable\n",
    "    dab_weight=0.0,\n",
    "    lr=1e-5,\n",
    "    batch_size=2,\n",
    "    layer_size=512,\n",
    "    nlayers=12,  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "    nhead=8,  # number of heads in nn.MultiheadAttention\n",
    "    dropout=0.2,  # dropout probability\n",
    "    schedule_ratio=0.9,  # ratio of epochs for learning rate schedule\n",
    "    save_eval_interval=5,\n",
    "    fast_transformer=True,\n",
    "    pre_norm=False,\n",
    "    amp=True,  # Automatic Mixed Precision\n",
    "    include_zero_gene=False,\n",
    "    freeze=False,  # freeze\n",
    "    DSBN=False,  # Domain-specific batch normalization\n",
    ")\n",
    "\n",
    "# ✅ **Initialize WandB**\n",
    "run = wandb.init(\n",
    "    config=hyperparameter_defaults,\n",
    "    dir=\"/data/cellular_aging/results/fine-tuning\",\n",
    "    project=\"scGPT\",\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    ")\n",
    "config = wandb.config\n",
    "set_seed(config.seed)\n",
    "\n",
    "# ✅ **Preprocessing Settings**\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
    "mask_ratio = config.mask_ratio\n",
    "mask_value = \"auto\"  # Always set to auto for masked values\n",
    "include_zero_gene = config.include_zero_gene  # Include zero genes in HVGs if True\n",
    "max_seq_len = 4417\n",
    "n_bins = config.n_bins\n",
    "\n",
    "# ✅ **Input/Output Representation**\n",
    "input_style = \"binned\"  # Options: \"normed_raw\", \"log1p\", or \"binned\"\n",
    "output_style = \"binned\"  # Options: \"normed_raw\", \"log1p\", or \"binned\"\n",
    "\n",
    "# ✅ **Training Settings**\n",
    "MLM = False\n",
    "CLS = True\n",
    "ADV = False\n",
    "CCE = False\n",
    "MVC = config.MVC\n",
    "ECS = config.ecs_thres > 0\n",
    "DAB = False\n",
    "INPUT_BATCH_LABELS = False\n",
    "input_emb_style = \"continuous\"\n",
    "cell_emb_style = \"cls\"\n",
    "adv_E_delay_epochs = 0\n",
    "adv_D_delay_epochs = 0\n",
    "mvc_decoder_style = \"inner product\"\n",
    "ecs_threshold = config.ecs_thres\n",
    "dab_weight = config.dab_weight\n",
    "explicit_zero_prob = MLM and include_zero_gene\n",
    "do_sample_in_train = False and explicit_zero_prob\n",
    "per_seq_batch_sample = False\n",
    "\n",
    "# ✅ **Optimizer Settings**\n",
    "lr = config.lr\n",
    "lr_ADV = 1e-3\n",
    "batch_size = config.batch_size\n",
    "eval_batch_size = config.batch_size\n",
    "epochs = config.epochs\n",
    "schedule_interval = 1\n",
    "\n",
    "# ✅ **Model Architecture Settings**\n",
    "fast_transformer = config.fast_transformer\n",
    "fast_transformer_backend = \"flash\"\n",
    "embsize = config.layer_size\n",
    "d_hid = config.layer_size\n",
    "nlayers = config.nlayers\n",
    "nhead = config.nhead\n",
    "dropout = config.dropout\n",
    "\n",
    "# ✅ **Logging & Evaluation**\n",
    "log_interval = 100\n",
    "save_eval_interval = config.save_eval_interval\n",
    "do_eval_scib_metrics = True\n",
    "\n",
    "# -----------------------------------\n",
    "# ✅ **Filtering Step: Load & Preprocess Dataset**\n",
    "# -----------------------------------\n",
    "\n",
    "# ✅ Load full dataset (AnnData format)\n",
    "adata = sc.read_h5ad('/data/cellular_aging/dataset/AIDA.h5ad')\n",
    "\n",
    "# ✅ Track Total Expression Before Filtering\n",
    "total_expression_before = adata.X.sum()\n",
    "\n",
    "# ✅ Load FINAL gene mapping (from BioMart + MyGene.info)\n",
    "df_final_mapping = pd.read_csv(\"final_gene_mapping.csv\")\n",
    "final_gene_dict = dict(zip(df_final_mapping[\"ensembl_id\"], df_final_mapping[\"gene_symbol\"]))\n",
    "\n",
    "# ✅ Extract Ensembl IDs & Apply Gene Mapping\n",
    "adata.var[\"ensembl_id\"] = adata.var_names.str.split(\".\").str[0]\n",
    "adata.var[\"gene_symbol\"] = adata.var[\"ensembl_id\"].map(final_gene_dict)\n",
    "\n",
    "# ✅ Load `vocab.json`\n",
    "vocab_path = \"/data/cellular_aging/references/scGPT_human_pretrained_model/vocab.json\"\n",
    "with open(vocab_path, \"r\") as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "# ✅ Convert vocab genes to a set\n",
    "vocab_genes = set(vocab.keys())\n",
    "\n",
    "# ✅ Filter dataset to keep only genes in `vocab.json`\n",
    "adata_filtered_vocab = adata[:, adata.var[\"gene_symbol\"].isin(vocab_genes)].copy()\n",
    "\n",
    "# ✅ Track Total Expression After Filtering\n",
    "total_expression_after = adata_filtered_vocab.X.sum()\n",
    "\n",
    "# ✅ Compute Gene & Expression Coverage\n",
    "gene_coverage_vocab = (adata_filtered_vocab.shape[1] / adata.shape[1]) * 100\n",
    "expression_coverage_vocab = (total_expression_after / total_expression_before) * 100\n",
    "\n",
    "# ✅ Print Final Summary\n",
    "print(\"\\n📊 **Final Gene Mapping & Expression Coverage Summary:**\")\n",
    "print(f\"🔹 Total Genes Before Vocab Filtering: {adata.shape[1]}\")\n",
    "print(f\"🔹 Total Genes After Vocab Filtering: {adata_filtered_vocab.shape[1]}\")\n",
    "print(f\"🔹 Total Expression Before Vocab Filtering: {total_expression_before:.2f}\")\n",
    "print(f\"🔹 Total Expression After Vocab Filtering: {total_expression_after:.2f}\")\n",
    "print(f\"✅ Gene Coverage After Vocab Filtering: {gene_coverage_vocab:.2f}%\")\n",
    "print(f\"✅ Expression Coverage After Vocab Filtering: {expression_coverage_vocab:.2f}%\")\n",
    "\n",
    "# ✅ **Step 1: Random Sampling**\n",
    "sample_fraction = 0.001  # Adjust as needed\n",
    "num_sample = int(sample_fraction * adata_filtered_vocab.n_obs)\n",
    "\n",
    "random_indices = np.random.choice(adata_filtered_vocab.n_obs, num_sample, replace=False)\n",
    "adata_sample = adata_filtered_vocab[random_indices, :].copy()\n",
    "print(f\"✅ Sampled dataset shape: {adata_sample.shape}\")\n",
    "\n",
    "# ✅ **Step 2: Convert to Sparse Format**\n",
    "adata_sample.X = csr_matrix(adata_sample.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97c8d097-3291-48d6-ba12-49395a01c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Settings for Input and Preprocessing\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
    "mask_ratio = config.mask_ratio\n",
    "mask_value = \"auto\"  # Always set to auto for masked values\n",
    "include_zero_gene = config.include_zero_gene  # Include zero genes in HVGs if True\n",
    "max_seq_len = 4417\n",
    "n_bins = config.n_bins\n",
    "\n",
    "# ✅ Input/Output Representation\n",
    "input_style = \"binned\"  # Options: \"normed_raw\", \"log1p\", or \"binned\"\n",
    "output_style = \"binned\"  # Options: \"normed_raw\", \"log1p\", or \"binned\"\n",
    "\n",
    "# ✅ Training Settings\n",
    "MLM = False  # Masked Language Modeling (MLM), always on\n",
    "CLS = True  # Enable Classification Objective\n",
    "ADV = False  # Adversarial Training for Batch Correction\n",
    "CCE = False  # Contrastive Cell Embedding Objective\n",
    "MVC = config.MVC  # Masked Value Prediction for Cell Embedding\n",
    "ECS = config.ecs_thres > 0  # Elastic Cell Similarity Objective (Enabled if > 0)\n",
    "DAB = False  # Domain Adaptation via Reverse Backpropagation (set to 2 for separate optimizer)\n",
    "INPUT_BATCH_LABELS = False  # Helps MLM and MVC, but not classifier\n",
    "input_emb_style = \"continuous\"  # Options: \"category\", \"continuous\", \"scaling\"\n",
    "cell_emb_style = \"cls\"  # Options: \"avg-pool\", \"w-pool\", \"cls\"\n",
    "adv_E_delay_epochs = 0  # Delay Adversarial Training (Encoder)\n",
    "adv_D_delay_epochs = 0  # Delay Adversarial Training (Discriminator)\n",
    "mvc_decoder_style = \"inner product\"\n",
    "ecs_threshold = config.ecs_thres\n",
    "dab_weight = config.dab_weight\n",
    "explicit_zero_prob = MLM and include_zero_gene  # Use explicit Bernoulli for zero values\n",
    "do_sample_in_train = False and explicit_zero_prob  # Sample Bernoulli in training\n",
    "per_seq_batch_sample = False  # Per-sequence batch sampling disabled\n",
    "\n",
    "# ✅ Optimizer Settings\n",
    "lr = config.lr  # Learning Rate\n",
    "lr_ADV = 1e-3  # Learning Rate for Adversarial Discriminator (if ADV is True)\n",
    "batch_size = config.batch_size\n",
    "eval_batch_size = config.batch_size\n",
    "epochs = config.epochs\n",
    "schedule_interval = 1  # Interval for learning rate scheduling\n",
    "\n",
    "# ✅ Model Architecture Settings\n",
    "fast_transformer = config.fast_transformer\n",
    "fast_transformer_backend = \"flash\"  # Options: \"linear\", \"flash\"\n",
    "embsize = config.layer_size  # Embedding Dimension\n",
    "d_hid = config.layer_size  # Hidden Dimension in TransformerEncoder\n",
    "nlayers = config.nlayers  # Number of Transformer Encoder Layers\n",
    "nhead = config.nhead  # Number of Attention Heads in MultiheadAttention\n",
    "dropout = config.dropout  # Dropout Probability\n",
    "\n",
    "# ✅ Logging & Evaluation\n",
    "log_interval = 100  # Log every 100 iterations\n",
    "save_eval_interval = config.save_eval_interval  # Save evaluation results every `save_eval_interval` epochs\n",
    "do_eval_scib_metrics = True  # Enable evaluation using SciB metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65e67513-0193-4e23-b657-1078256d3c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, loader: DataLoader, return_raw: bool = False) -> Union[float, Tuple[float, float]]:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the validation/test dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_error = 0.0\n",
    "    total_dab = 0.0\n",
    "    total_num = 0\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in loader:\n",
    "            input_gene_ids = batch_data[\"gene_ids\"].to(device)\n",
    "            input_values = batch_data[\"values\"].to(device)\n",
    "            target_values = batch_data[\"target_values\"].to(device)\n",
    "            batch_labels = batch_data[\"batch_labels\"].to(device)\n",
    "            age_labels = batch_data[\"age_labels\"].to(device)\n",
    "\n",
    "            src_key_padding_mask = input_gene_ids.eq(vocab[pad_token])\n",
    "            \n",
    "            with torch.cuda.amp.autocast(enabled=config.amp):\n",
    "                output_dict = model(\n",
    "                    input_gene_ids,\n",
    "                    input_values,\n",
    "                    src_key_padding_mask=src_key_padding_mask,\n",
    "                    batch_labels=batch_labels if INPUT_BATCH_LABELS or config.DSBN else None,\n",
    "                    CLS=CLS,  # Only classification used here, disable MLM/CCE\n",
    "                    CCE=False,\n",
    "                    MVC=False,\n",
    "                    ECS=False,\n",
    "                    do_sample=do_sample_in_train,\n",
    "                )\n",
    "\n",
    "                output_values = output_dict[\"cls_output\"]\n",
    "                loss = criterion_cls(output_values, age_labels)\n",
    "\n",
    "                if DAB:\n",
    "                    loss_dab = criterion_dab(output_dict[\"dab_output\"], batch_labels)\n",
    "\n",
    "            total_loss += loss.item() * len(input_gene_ids)\n",
    "            accuracy = (output_values.argmax(1) == age_labels).sum().item()\n",
    "            total_error += (1 - accuracy / len(input_gene_ids)) * len(input_gene_ids)\n",
    "            total_dab += loss_dab.item() * len(input_gene_ids) if DAB else 0.0\n",
    "            total_num += len(input_gene_ids)\n",
    "\n",
    "            preds = output_values.argmax(1).cpu().numpy()\n",
    "            predictions.append(preds)\n",
    "\n",
    "    # Log metrics\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"valid/mse\": total_loss / total_num,\n",
    "            \"valid/err\": total_error / total_num,\n",
    "            \"valid/dab\": total_dab / total_num,\n",
    "            \"valid/sum_mse_dab\": (total_loss + dab_weight * total_dab) / total_num,\n",
    "            \"epoch\": epoch,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if return_raw:\n",
    "        return np.concatenate(predictions, axis=0)\n",
    "\n",
    "    return total_loss / total_num, total_error / total_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d289874-698d-4433-a3dd-266354877c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ **Log Best Model Metrics**\n",
    "wandb.log(\n",
    "    {\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"best_model_epoch\": best_model_epoch,\n",
    "    }\n",
    ")\n",
    "\n",
    "# ✅ **Save Best Model**\n",
    "best_model_path = save_dir / \"best_model.pt\"\n",
    "torch.save(best_model.state_dict(), best_model_path)\n",
    "logger.info(f\"✅ Best model saved at: {best_model_path}\")\n",
    "\n",
    "# ✅ **Cleanup Resources**\n",
    "wandb.finish()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()  # Free up GPU memory\n",
    "logger.info(\"✅ Cleanup complete. WandB session closed, memory freed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
